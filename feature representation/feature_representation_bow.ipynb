{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d05aa73-f694-40ed-b2f7-878d14bb0e33",
   "metadata": {},
   "source": [
    "# **FEATURE EXTRACTION - BAG OF WORDS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2421a126-1469-401b-b51b-8d35d483eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import ast\n",
    "import re\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "#data visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "#NLP & ML libraries\n",
    "from gensim import corpora\n",
    "\n",
    "from nltk import FreqDist\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c6bdc3-33ce-46f4-84c7-3e2d1d9d189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed so that code output is deterministic\n",
    "random.seed(0)  # Set the seed for Python's random module\n",
    "np.random.seed(0)  # Set the seed for NumPy's random module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a28177-4795-41eb-93e7-2f20f968521d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>date_created</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfou07</td>\n",
       "      <td>2021-04-05 13:13:23</td>\n",
       "      <td>2021</td>\n",
       "      <td>I am single and I have not traveled to any cun...</td>\n",
       "      <td>single travel past</td>\n",
       "      <td>[single, travel, past]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfrgpe</td>\n",
       "      <td>2021-04-05 13:56:09</td>\n",
       "      <td>2021</td>\n",
       "      <td>What happens when you shop at dragon mart...</td>\n",
       "      <td>shop dragon mart</td>\n",
       "      <td>[shop, dragon, mart]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>gthiiwi</td>\n",
       "      <td>2021-04-05 23:18:56</td>\n",
       "      <td>2021</td>\n",
       "      <td>That’s just absolutely hilarious, is this in t...</td>\n",
       "      <td>hilarious spring souk</td>\n",
       "      <td>[hilarious, spring, souk]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtgfl4c</td>\n",
       "      <td>2021-04-05 18:21:42</td>\n",
       "      <td>2021</td>\n",
       "      <td>Is reel cinema and roxy part of emaar?</td>\n",
       "      <td>reel cinema roxy emaar</td>\n",
       "      <td>[reel, cinema, roxy, emaar]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>gth5wdv</td>\n",
       "      <td>2021-04-05 21:42:41</td>\n",
       "      <td>2021</td>\n",
       "      <td>An innocent redditor here...can someone pls ex...</td>\n",
       "      <td>innocent pls explain everyday</td>\n",
       "      <td>[innocent, pls, explain, everyday]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_type       ID         date_created  year  \\\n",
       "0   comment  gtfou07  2021-04-05 13:13:23  2021   \n",
       "1   comment  gtfrgpe  2021-04-05 13:56:09  2021   \n",
       "2   comment  gthiiwi  2021-04-05 23:18:56  2021   \n",
       "3   comment  gtgfl4c  2021-04-05 18:21:42  2021   \n",
       "4   comment  gth5wdv  2021-04-05 21:42:41  2021   \n",
       "\n",
       "                                           long_text  \\\n",
       "0  I am single and I have not traveled to any cun...   \n",
       "1       What happens when you shop at dragon mart...   \n",
       "2  That’s just absolutely hilarious, is this in t...   \n",
       "3             Is reel cinema and roxy part of emaar?   \n",
       "4  An innocent redditor here...can someone pls ex...   \n",
       "\n",
       "                      clean_text                              tokens  \\\n",
       "0             single travel past              [single, travel, past]   \n",
       "1               shop dragon mart                [shop, dragon, mart]   \n",
       "2          hilarious spring souk           [hilarious, spring, souk]   \n",
       "3         reel cinema roxy emaar         [reel, cinema, roxy, emaar]   \n",
       "4  innocent pls explain everyday  [innocent, pls, explain, everyday]   \n",
       "\n",
       "   word_count  \n",
       "0           3  \n",
       "1           3  \n",
       "2           3  \n",
       "3           4  \n",
       "4           4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import cleaned data\n",
    "\n",
    "def list_converter(text):\n",
    "    #to revert list->str conversion from pd.read_csv\n",
    "    return ast.literal_eval(text)\n",
    "\n",
    "\n",
    "data = pd.read_csv('../Data/training_data.csv', converters ={'tokens':list_converter})\n",
    "data = data.drop(columns = ['index'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07470ff3-9ec0-415a-b720-d24378ad2181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65987 entries, 0 to 65986\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   text_type     65987 non-null  object\n",
      " 1   ID            65987 non-null  object\n",
      " 2   date_created  65987 non-null  object\n",
      " 3   year          65987 non-null  int64 \n",
      " 4   long_text     65987 non-null  object\n",
      " 5   clean_text    65987 non-null  object\n",
      " 6   tokens        65987 non-null  object\n",
      " 7   word_count    65987 non-null  int64 \n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5903cae-6eea-4ece-8653-1814fdaeb153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['single travel past',\n",
       " 'shop dragon mart',\n",
       " 'hilarious spring souk',\n",
       " 'reel cinema roxy emaar',\n",
       " 'innocent pls explain everyday']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert df['tokens'] to list of strings for bag-of-words model\n",
    "docs = data['tokens'].apply(lambda token: ' '.join(token)).tolist()\n",
    "\n",
    "docs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61f81992-6b19-4644-9608-39e829d5e748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 03:02:03,189 : INFO : collecting all words and their counts\n",
      "2023-08-10 03:02:03,192 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2023-08-10 03:02:03,923 : INFO : PROGRESS: at sentence #10000, processed 645093 words and 606 word types\n",
      "2023-08-10 03:02:04,652 : INFO : PROGRESS: at sentence #20000, processed 1290938 words and 619 word types\n",
      "2023-08-10 03:02:05,364 : INFO : PROGRESS: at sentence #30000, processed 1915954 words and 620 word types\n",
      "2023-08-10 03:02:06,089 : INFO : PROGRESS: at sentence #40000, processed 2570254 words and 621 word types\n",
      "2023-08-10 03:02:06,815 : INFO : PROGRESS: at sentence #50000, processed 3217436 words and 621 word types\n",
      "2023-08-10 03:02:07,512 : INFO : PROGRESS: at sentence #60000, processed 3840543 words and 622 word types\n",
      "2023-08-10 03:02:08,163 : INFO : collected 622 token types (unigram + bigrams) from a corpus of 4421536 words and 65987 sentences\n",
      "2023-08-10 03:02:08,164 : INFO : merged Phrases<622 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000>\n",
      "2023-08-10 03:02:08,166 : INFO : Phrases lifecycle event {'msg': 'built Phrases<622 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000> in 4.98s', 'datetime': '2023-08-10T03:02:08.166640', 'gensim': '4.3.1', 'python': '3.10.1 (v3.10.1:2cd268a3a9, Dec  6 2021, 14:28:59) [Clang 13.0.0 (clang-1300.0.29.3)]', 'platform': 'macOS-10.14.6-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m bigram[docs[idx]]:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m token:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# Token is a bigram, add to document.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m         \u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(token)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663fc85-a00f-443f-b7f2-64bf2b2db81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim bag of words documentation page\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = corpora.Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "#dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
    "\n",
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "projectenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
