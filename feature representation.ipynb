{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9547f2e6-52f6-4677-8def-141bfe80b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import ast\n",
    "import re\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "#spelling correction\n",
    "import enchant\n",
    "from spellchecker import SpellChecker\n",
    "from autocorrect import Speller\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "#data visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "#NLP & ML libraries\n",
    "from nltk import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf3d1755-aa51-4db4-8a6a-72f2a4abd408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cleaned data\n",
    "\n",
    "def list_converter(text):\n",
    "    #to revert list->str conversion from pd.read_csv\n",
    "    return ast.literal_eval(text)\n",
    "\n",
    "\n",
    "data = pd.read_csv('Data/training_corpus.csv', converters ={'tokens':list_converter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8226c20a-4cff-45e3-b0f6-2d80eadb30b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>gtfo2hl</td>\n",
       "      <td>2021</td>\n",
       "      <td>*Cuntry roads, take me hoem*</td>\n",
       "      <td>cuntry roads hoem</td>\n",
       "      <td>3</td>\n",
       "      <td>[cuntry, road, hoem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>comment</td>\n",
       "      <td>gtfqkbv</td>\n",
       "      <td>2021</td>\n",
       "      <td>That’s been there for several years, sent a pi...</td>\n",
       "      <td>years sent pic cuntry friend long time ago</td>\n",
       "      <td>8</td>\n",
       "      <td>[year, send, pic, cuntry, friend, long, time, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>comment</td>\n",
       "      <td>gtfou07</td>\n",
       "      <td>2021</td>\n",
       "      <td>I am single and I have not traveled to any cun...</td>\n",
       "      <td>single traveled cuntry past year</td>\n",
       "      <td>5</td>\n",
       "      <td>[single, travel, cuntry, past, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>comment</td>\n",
       "      <td>gtfrgpe</td>\n",
       "      <td>2021</td>\n",
       "      <td>What happens when you shop at dragon mart...</td>\n",
       "      <td>happens shop dragon mart</td>\n",
       "      <td>4</td>\n",
       "      <td>[happen, shop, dragon, mart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>comment</td>\n",
       "      <td>gthiiwi</td>\n",
       "      <td>2021</td>\n",
       "      <td>That’s just absolutely hilarious, is this in t...</td>\n",
       "      <td>absolutely hilarious springs souk</td>\n",
       "      <td>4</td>\n",
       "      <td>[absolutely, hilarious, spring, souk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99181</th>\n",
       "      <td>100367</td>\n",
       "      <td>submission</td>\n",
       "      <td>14f46ji</td>\n",
       "      <td>2023</td>\n",
       "      <td>Best beauty saloons in Dubai? Hello fellas, I ...</td>\n",
       "      <td>best beauty saloons dubai hello fellas moved w...</td>\n",
       "      <td>35</td>\n",
       "      <td>[good, beauty, saloon, dubai, hello, fellas, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99182</th>\n",
       "      <td>100368</td>\n",
       "      <td>submission</td>\n",
       "      <td>14f4uyi</td>\n",
       "      <td>2023</td>\n",
       "      <td>Found the r/dubai redditors who kept telling m...</td>\n",
       "      <td>found r dubai redditors kept telling know navi...</td>\n",
       "      <td>10</td>\n",
       "      <td>[find, r, dubai, redditor, keep, tell, know, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99183</th>\n",
       "      <td>100369</td>\n",
       "      <td>submission</td>\n",
       "      <td>14f4ri3</td>\n",
       "      <td>2023</td>\n",
       "      <td>Scam ? Healthy.line My sister has a CBD debit ...</td>\n",
       "      <td>scam healthy line sister cbd debit card month ...</td>\n",
       "      <td>47</td>\n",
       "      <td>[scam, healthy, line, sister, cbd, debit, card...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99184</th>\n",
       "      <td>100370</td>\n",
       "      <td>submission</td>\n",
       "      <td>14f4k3r</td>\n",
       "      <td>2023</td>\n",
       "      <td>Thoughts on Expo City properties? Anyone else ...</td>\n",
       "      <td>thoughts expo city properties checked expo cit...</td>\n",
       "      <td>21</td>\n",
       "      <td>[thought, expo, city, property, check, expo, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99185</th>\n",
       "      <td>100371</td>\n",
       "      <td>submission</td>\n",
       "      <td>14f8d30</td>\n",
       "      <td>2023</td>\n",
       "      <td>What to do when the neighbour parks like this?...</td>\n",
       "      <td>neighbour parks like hello dubai community guy...</td>\n",
       "      <td>19</td>\n",
       "      <td>[neighbour, park, like, hello, dubai, communit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99186 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index   text_type       ID  year  \\\n",
       "0           0     comment  gtfo2hl  2021   \n",
       "1           1     comment  gtfqkbv  2021   \n",
       "2           2     comment  gtfou07  2021   \n",
       "3           3     comment  gtfrgpe  2021   \n",
       "4           4     comment  gthiiwi  2021   \n",
       "...       ...         ...      ...   ...   \n",
       "99181  100367  submission  14f46ji  2023   \n",
       "99182  100368  submission  14f4uyi  2023   \n",
       "99183  100369  submission  14f4ri3  2023   \n",
       "99184  100370  submission  14f4k3r  2023   \n",
       "99185  100371  submission  14f8d30  2023   \n",
       "\n",
       "                                               long_text  \\\n",
       "0                           *Cuntry roads, take me hoem*   \n",
       "1      That’s been there for several years, sent a pi...   \n",
       "2      I am single and I have not traveled to any cun...   \n",
       "3           What happens when you shop at dragon mart...   \n",
       "4      That’s just absolutely hilarious, is this in t...   \n",
       "...                                                  ...   \n",
       "99181  Best beauty saloons in Dubai? Hello fellas, I ...   \n",
       "99182  Found the r/dubai redditors who kept telling m...   \n",
       "99183  Scam ? Healthy.line My sister has a CBD debit ...   \n",
       "99184  Thoughts on Expo City properties? Anyone else ...   \n",
       "99185  What to do when the neighbour parks like this?...   \n",
       "\n",
       "                                              clean_text  word_count  \\\n",
       "0                                      cuntry roads hoem           3   \n",
       "1             years sent pic cuntry friend long time ago           8   \n",
       "2                       single traveled cuntry past year           5   \n",
       "3                               happens shop dragon mart           4   \n",
       "4                      absolutely hilarious springs souk           4   \n",
       "...                                                  ...         ...   \n",
       "99181  best beauty saloons dubai hello fellas moved w...          35   \n",
       "99182  found r dubai redditors kept telling know navi...          10   \n",
       "99183  scam healthy line sister cbd debit card month ...          47   \n",
       "99184  thoughts expo city properties checked expo cit...          21   \n",
       "99185  neighbour parks like hello dubai community guy...          19   \n",
       "\n",
       "                                                  tokens  \n",
       "0                                   [cuntry, road, hoem]  \n",
       "1      [year, send, pic, cuntry, friend, long, time, ...  \n",
       "2                   [single, travel, cuntry, past, year]  \n",
       "3                           [happen, shop, dragon, mart]  \n",
       "4                  [absolutely, hilarious, spring, souk]  \n",
       "...                                                  ...  \n",
       "99181  [good, beauty, saloon, dubai, hello, fellas, m...  \n",
       "99182  [find, r, dubai, redditor, keep, tell, know, n...  \n",
       "99183  [scam, healthy, line, sister, cbd, debit, card...  \n",
       "99184  [thought, expo, city, property, check, expo, c...  \n",
       "99185  [neighbour, park, like, hello, dubai, communit...  \n",
       "\n",
       "[99186 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843da22-70c0-4ccd-a846-4bafced9bc6c",
   "metadata": {},
   "source": [
    "## **Bag of Words Model** (from Sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5866e12-3ae5-4d25-9381-8aa2f94e0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization was done on tokens, not clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c22f0f79-5dbe-41f7-8b31-18be80e5cec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<99186x47566 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1262927 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create CountVectorizer object\n",
    "cv = CountVectorizer()\n",
    "\n",
    "#convert corpus to matrix of word vectors\n",
    "#bow_matrix = vectorizer.fit_transform(data)\n",
    "\n",
    "#create vocabulary with indices for each word\n",
    "#cv_vectorizer = vectorizer.fit(data['clean_text'].values)\n",
    "\n",
    "#vocabulary = vectorizer.vocabulary_\n",
    "#print unique words and their indices\n",
    "#print (\"vocabulary: \", vocabulary.items()[:5])\n",
    "\n",
    "#create word vectors for each word\n",
    "bow_matrix = cv.fit_transform(data['clean_text'].values)\n",
    "\n",
    "#print matrix as 2-d vector arrays\n",
    "#print (bow_matrix.toarray())\n",
    "\n",
    "bow_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ffe3c0-cd0d-4051-9be3-74e236bd158c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
