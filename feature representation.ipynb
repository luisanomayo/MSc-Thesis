{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9547f2e6-52f6-4677-8def-141bfe80b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import ast\n",
    "import re\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import time\n",
    "\n",
    "#spelling correction\n",
    "import enchant\n",
    "from spellchecker import SpellChecker\n",
    "from autocorrect import Speller\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "#data visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "#NLP & ML libraries\n",
    "from nltk import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b5f038b-75a9-474c-91bc-520d250c516d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_colwidth')\n",
    "pd.reset_option ('display.max_column')\n",
    "\n",
    "#pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3d1755-aa51-4db4-8a6a-72f2a4abd408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cleaned data\n",
    "\n",
    "def list_converter(text):\n",
    "    #to revert list->str conversion from pd.read_csv\n",
    "    return ast.literal_eval(text)\n",
    "\n",
    "\n",
    "data = pd.read_csv('Data/training_corpus.csv', converters ={'tokens':list_converter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8226c20a-4cff-45e3-b0f6-2d80eadb30b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfo2hl</td>\n",
       "      <td>2021</td>\n",
       "      <td>*Cuntry roads, take me hoem*</td>\n",
       "      <td>cuntry roads hoem</td>\n",
       "      <td>3</td>\n",
       "      <td>[cuntry, road, hoem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfqkbv</td>\n",
       "      <td>2021</td>\n",
       "      <td>That’s been there for several years, sent a pi...</td>\n",
       "      <td>years sent pic cuntry friend long time ago</td>\n",
       "      <td>8</td>\n",
       "      <td>[year, send, pic, cuntry, friend, long, time, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfou07</td>\n",
       "      <td>2021</td>\n",
       "      <td>I am single and I have not traveled to any cun...</td>\n",
       "      <td>single traveled cuntry past year</td>\n",
       "      <td>5</td>\n",
       "      <td>[single, travel, cuntry, past, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfrgpe</td>\n",
       "      <td>2021</td>\n",
       "      <td>What happens when you shop at dragon mart...</td>\n",
       "      <td>happens shop dragon mart</td>\n",
       "      <td>4</td>\n",
       "      <td>[happen, shop, dragon, mart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>gthiiwi</td>\n",
       "      <td>2021</td>\n",
       "      <td>That’s just absolutely hilarious, is this in t...</td>\n",
       "      <td>absolutely hilarious springs souk</td>\n",
       "      <td>4</td>\n",
       "      <td>[absolutely, hilarious, spring, souk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99181</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f46ji</td>\n",
       "      <td>2023</td>\n",
       "      <td>Best beauty saloons in Dubai? Hello fellas, I ...</td>\n",
       "      <td>best beauty saloons dubai hello fellas moved w...</td>\n",
       "      <td>35</td>\n",
       "      <td>[good, beauty, saloon, dubai, hello, fellas, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99182</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f4uyi</td>\n",
       "      <td>2023</td>\n",
       "      <td>Found the r/dubai redditors who kept telling m...</td>\n",
       "      <td>found r dubai redditors kept telling know navi...</td>\n",
       "      <td>10</td>\n",
       "      <td>[find, r, dubai, redditor, keep, tell, know, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99183</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f4ri3</td>\n",
       "      <td>2023</td>\n",
       "      <td>Scam ? Healthy.line My sister has a CBD debit ...</td>\n",
       "      <td>scam healthy line sister cbd debit card month ...</td>\n",
       "      <td>47</td>\n",
       "      <td>[scam, healthy, line, sister, cbd, debit, card...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99184</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f4k3r</td>\n",
       "      <td>2023</td>\n",
       "      <td>Thoughts on Expo City properties? Anyone else ...</td>\n",
       "      <td>thoughts expo city properties checked expo cit...</td>\n",
       "      <td>21</td>\n",
       "      <td>[thought, expo, city, property, check, expo, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99185</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f8d30</td>\n",
       "      <td>2023</td>\n",
       "      <td>What to do when the neighbour parks like this?...</td>\n",
       "      <td>neighbour parks like hello dubai community guy...</td>\n",
       "      <td>19</td>\n",
       "      <td>[neighbour, park, like, hello, dubai, communit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99186 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_type       ID  year  \\\n",
       "0         comment  gtfo2hl  2021   \n",
       "1         comment  gtfqkbv  2021   \n",
       "2         comment  gtfou07  2021   \n",
       "3         comment  gtfrgpe  2021   \n",
       "4         comment  gthiiwi  2021   \n",
       "...           ...      ...   ...   \n",
       "99181  submission  14f46ji  2023   \n",
       "99182  submission  14f4uyi  2023   \n",
       "99183  submission  14f4ri3  2023   \n",
       "99184  submission  14f4k3r  2023   \n",
       "99185  submission  14f8d30  2023   \n",
       "\n",
       "                                               long_text  \\\n",
       "0                           *Cuntry roads, take me hoem*   \n",
       "1      That’s been there for several years, sent a pi...   \n",
       "2      I am single and I have not traveled to any cun...   \n",
       "3           What happens when you shop at dragon mart...   \n",
       "4      That’s just absolutely hilarious, is this in t...   \n",
       "...                                                  ...   \n",
       "99181  Best beauty saloons in Dubai? Hello fellas, I ...   \n",
       "99182  Found the r/dubai redditors who kept telling m...   \n",
       "99183  Scam ? Healthy.line My sister has a CBD debit ...   \n",
       "99184  Thoughts on Expo City properties? Anyone else ...   \n",
       "99185  What to do when the neighbour parks like this?...   \n",
       "\n",
       "                                              clean_text  word_count  \\\n",
       "0                                      cuntry roads hoem           3   \n",
       "1             years sent pic cuntry friend long time ago           8   \n",
       "2                       single traveled cuntry past year           5   \n",
       "3                               happens shop dragon mart           4   \n",
       "4                      absolutely hilarious springs souk           4   \n",
       "...                                                  ...         ...   \n",
       "99181  best beauty saloons dubai hello fellas moved w...          35   \n",
       "99182  found r dubai redditors kept telling know navi...          10   \n",
       "99183  scam healthy line sister cbd debit card month ...          47   \n",
       "99184  thoughts expo city properties checked expo cit...          21   \n",
       "99185  neighbour parks like hello dubai community guy...          19   \n",
       "\n",
       "                                                  tokens  \n",
       "0                                   [cuntry, road, hoem]  \n",
       "1      [year, send, pic, cuntry, friend, long, time, ...  \n",
       "2                   [single, travel, cuntry, past, year]  \n",
       "3                           [happen, shop, dragon, mart]  \n",
       "4                  [absolutely, hilarious, spring, souk]  \n",
       "...                                                  ...  \n",
       "99181  [good, beauty, saloon, dubai, hello, fellas, m...  \n",
       "99182  [find, r, dubai, redditor, keep, tell, know, n...  \n",
       "99183  [scam, healthy, line, sister, cbd, debit, card...  \n",
       "99184  [thought, expo, city, property, check, expo, c...  \n",
       "99185  [neighbour, park, like, hello, dubai, communit...  \n",
       "\n",
       "[99186 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns = ['index'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843da22-70c0-4ccd-a846-4bafced9bc6c",
   "metadata": {},
   "source": [
    "## **Bag of Words Model** (from Sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6bf59ec2-a588-4291-8c54-9a4eb0b6e511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program took 42.788 seconds to complete. The ngram representation had 39810 features.\n"
     ]
    }
   ],
   "source": [
    "#create instance of CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "#convert list of tokenized words to strings\n",
    "input_data = data['tokens'].apply(lambda token: ' '.join(token))\n",
    "\n",
    "#create matrix of word vectors\n",
    "X_bow = cv.fit_transform(input_data)\n",
    "\n",
    "print (\"The program took %.3f seconds to complete. The ngram representation had %i features.\" % (time.time() - start_time, X_bow.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "59bd39e7-99b5-4792-be01-0eea6987f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get feature names\n",
    "bow_features = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "86c201b3-daae-4c5a-ab99-ec05ae7d883a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>agent</th>\n",
       "      <th>asian</th>\n",
       "      <th>asset</th>\n",
       "      <th>brodsky</th>\n",
       "      <th>buy</th>\n",
       "      <th>car</th>\n",
       "      <th>center</th>\n",
       "      <th>check</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>thing</th>\n",
       "      <th>time</th>\n",
       "      <th>town</th>\n",
       "      <th>trade</th>\n",
       "      <th>uni</th>\n",
       "      <th>village</th>\n",
       "      <th>visit</th>\n",
       "      <th>want</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dubai world trade center expo site rest taken ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uni enjoyed felt brodsky comopolitan like town...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visit aus fri aus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kind intrigued feel reluctant time car maybe y...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>real estate agent rereading sounds pro real es...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  agent  asian  asset  \\\n",
       "0  dubai world trade center expo site rest taken ...      0      0      0   \n",
       "1  uni enjoyed felt brodsky comopolitan like town...      0      0      0   \n",
       "2                                  visit aus fri aus      0      0      0   \n",
       "3  kind intrigued feel reluctant time car maybe y...      0      1      0   \n",
       "4  real estate agent rereading sounds pro real es...      1      0      1   \n",
       "\n",
       "   brodsky  buy  car  center  check  city  ...  thing  time  town  trade  uni  \\\n",
       "0        0    0    0       1      0     0  ...      0     0     0      1    0   \n",
       "1        1    0    0       0      0     1  ...      0     0     1      0    1   \n",
       "2        0    0    0       0      0     0  ...      0     0     0      0    0   \n",
       "3        0    0    1       0      1     0  ...      0     1     0      0    0   \n",
       "4        0    1    0       0      0     0  ...      1     1     0      0    0   \n",
       "\n",
       "   village  visit  want  world  year  \n",
       "0        0      0     0      1     0  \n",
       "1        0      0     0      0     0  \n",
       "2        0      1     0      0     0  \n",
       "3        1      0     1      0     1  \n",
       "4        0      0     0      0     0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tabular presentation of a sample of the bag of words representation\n",
    "text_df = data['clean_text'].loc[8000:8004].copy()\n",
    "bow_df = pd.DataFrame(X_bow[8000:8005].toarray(), columns = bow_features)\n",
    "\n",
    "text_bow = bow_df.copy()\n",
    "text_bow = text_bow.loc[:, (text_bow == 1).any()]\n",
    "\n",
    "text_bow.insert(0, 'clean_text', text_df.values)\n",
    "\n",
    "text_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25ccfb-677a-414c-aabf-d8dda8c1a6f5",
   "metadata": {},
   "source": [
    "## **N-Grams Model** with Sklearn's CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290186d0-7ecc-476b-94ef-e5012a21bfa7",
   "metadata": {},
   "source": [
    "### **Bi-Grams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6e93161b-e256-496e-9c5f-ebbf7702e39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program took 5.903 seconds to complete. The ngram representation had 771375 features.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# create bi_gram instance of CountVectorizer\n",
    "bi_cv = CountVectorizer(analyzer = 'word', ngram_range = (2,2))\n",
    "\n",
    "\n",
    "#create matrix of word vectors\n",
    "X_bigram = bi_cv.fit_transform(input_data)\n",
    "\n",
    "print (\"The program took %.3f seconds to complete. The ngram representation had %i features.\" % (time.time() - start_time, X_bigram.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0c483ebb-8c29-438e-9695-43de9b9dc719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>agent rereading</th>\n",
       "      <th>asian village</th>\n",
       "      <th>asset price</th>\n",
       "      <th>aus fri</th>\n",
       "      <th>brodsky comopolitan</th>\n",
       "      <th>buy peak</th>\n",
       "      <th>car maybe</th>\n",
       "      <th>center expo</th>\n",
       "      <th>chance repricing</th>\n",
       "      <th>...</th>\n",
       "      <th>time car</th>\n",
       "      <th>time stay</th>\n",
       "      <th>town city</th>\n",
       "      <th>trade center</th>\n",
       "      <th>uni enjoy</th>\n",
       "      <th>village goody</th>\n",
       "      <th>visit aus</th>\n",
       "      <th>want check</th>\n",
       "      <th>world trade</th>\n",
       "      <th>year want</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dubai world trade center expo site rest taken ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uni enjoyed felt brodsky comopolitan like town...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visit aus fri aus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kind intrigued feel reluctant time car maybe y...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>real estate agent rereading sounds pro real es...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  agent rereading  \\\n",
       "0  dubai world trade center expo site rest taken ...                0   \n",
       "1  uni enjoyed felt brodsky comopolitan like town...                0   \n",
       "2                                  visit aus fri aus                0   \n",
       "3  kind intrigued feel reluctant time car maybe y...                0   \n",
       "4  real estate agent rereading sounds pro real es...                1   \n",
       "\n",
       "   asian village  asset price  aus fri  brodsky comopolitan  buy peak  \\\n",
       "0              0            0        0                    0         0   \n",
       "1              0            0        0                    1         0   \n",
       "2              0            0        1                    0         0   \n",
       "3              1            0        0                    0         0   \n",
       "4              0            1        0                    0         1   \n",
       "\n",
       "   car maybe  center expo  chance repricing  ...  time car  time stay  \\\n",
       "0          0            1                 0  ...         0          0   \n",
       "1          0            0                 0  ...         0          0   \n",
       "2          0            0                 0  ...         0          0   \n",
       "3          1            0                 0  ...         1          0   \n",
       "4          0            0                 1  ...         0          1   \n",
       "\n",
       "   town city  trade center  uni enjoy  village goody  visit aus  want check  \\\n",
       "0          0             1          0              0          0           0   \n",
       "1          1             0          1              0          0           0   \n",
       "2          0             0          0              0          1           0   \n",
       "3          0             0          0              1          0           1   \n",
       "4          0             0          0              0          0           0   \n",
       "\n",
       "   world trade  year want  \n",
       "0            1          0  \n",
       "1            0          0  \n",
       "2            0          0  \n",
       "3            0          1  \n",
       "4            0          0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get feature names\n",
    "bigram_features = bi_cv.get_feature_names()\n",
    "\n",
    "#tabular presentation of a sample of the bag of words representation\n",
    "\n",
    "bigram_df = pd.DataFrame(X_bigram[8000:8005].toarray(), columns = bigram_features)\n",
    "\n",
    "text_bigram = bigram_df.copy()\n",
    "text_bigram = text_bigram.loc[:, (text_bigram == 1).any()]\n",
    "\n",
    "text_bigram.insert(0, 'clean_text', text_df.values)\n",
    "\n",
    "text_bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3ba89-ab89-42ad-a218-8c6cf2c1bc7a",
   "metadata": {},
   "source": [
    "### **Tri-Grams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cab173-f712-4bd7-b9ae-19e2f154615d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
