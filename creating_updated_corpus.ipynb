{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8af7d744-7874-47d3-b827-490ba6bf2885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdfd0f55-fa3f-4e39-8e41-1ed0eb0a363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /Users/amenaghawon/Documents/projectenv/lib/python3.10/site-packages (10.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adaf4294-c19d-4bea-9c14-c9e58d6473cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import string\n",
    "import csv\n",
    "\n",
    "from gensim.utils import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9712d89b-d751-4f49-a179-26f063727490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cleaned data\n",
    "\n",
    "def list_converter(text):\n",
    "    #to revert list->str conversion from pd.read_csv\n",
    "    return ast.literal_eval(text)\n",
    "\n",
    "\n",
    "data = pd.read_csv('Data/training_corpus.csv', converters ={'tokens':list_converter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f492298-d9b9-444b-a52d-7ac164f18a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99186, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfo2hl</td>\n",
       "      <td>2021</td>\n",
       "      <td>*Cuntry roads, take me hoem*</td>\n",
       "      <td>cuntry roads hoem</td>\n",
       "      <td>3</td>\n",
       "      <td>[cuntry, road, hoem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfqkbv</td>\n",
       "      <td>2021</td>\n",
       "      <td>That’s been there for several years, sent a pi...</td>\n",
       "      <td>years sent pic cuntry friend long time ago</td>\n",
       "      <td>8</td>\n",
       "      <td>[year, send, pic, cuntry, friend, long, time, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfou07</td>\n",
       "      <td>2021</td>\n",
       "      <td>I am single and I have not traveled to any cun...</td>\n",
       "      <td>single traveled cuntry past year</td>\n",
       "      <td>5</td>\n",
       "      <td>[single, travel, cuntry, past, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfrgpe</td>\n",
       "      <td>2021</td>\n",
       "      <td>What happens when you shop at dragon mart...</td>\n",
       "      <td>happens shop dragon mart</td>\n",
       "      <td>4</td>\n",
       "      <td>[happen, shop, dragon, mart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>gthiiwi</td>\n",
       "      <td>2021</td>\n",
       "      <td>That’s just absolutely hilarious, is this in t...</td>\n",
       "      <td>absolutely hilarious springs souk</td>\n",
       "      <td>4</td>\n",
       "      <td>[absolutely, hilarious, spring, souk]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_type       ID  year                                          long_text  \\\n",
       "0   comment  gtfo2hl  2021                       *Cuntry roads, take me hoem*   \n",
       "1   comment  gtfqkbv  2021  That’s been there for several years, sent a pi...   \n",
       "2   comment  gtfou07  2021  I am single and I have not traveled to any cun...   \n",
       "3   comment  gtfrgpe  2021       What happens when you shop at dragon mart...   \n",
       "4   comment  gthiiwi  2021  That’s just absolutely hilarious, is this in t...   \n",
       "\n",
       "                                   clean_text  word_count  \\\n",
       "0                           cuntry roads hoem           3   \n",
       "1  years sent pic cuntry friend long time ago           8   \n",
       "2            single traveled cuntry past year           5   \n",
       "3                    happens shop dragon mart           4   \n",
       "4           absolutely hilarious springs souk           4   \n",
       "\n",
       "                                              tokens  \n",
       "0                               [cuntry, road, hoem]  \n",
       "1  [year, send, pic, cuntry, friend, long, time, ...  \n",
       "2               [single, travel, cuntry, past, year]  \n",
       "3                       [happen, shop, dragon, mart]  \n",
       "4              [absolutely, hilarious, spring, souk]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns = ['index'])\n",
    "print (data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8486eed9-b18e-44a4-ad70-4e2f240f6068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include column with additional stopwords removal\n",
    "#created the filtered corpus from another notebook and imported it here for use\n",
    "# Read the file\n",
    "with open('updated_corpus new2.txt', 'r') as f:\n",
    "    updated_tokens = f.readlines()\n",
    "\n",
    "# Remove newline characters\n",
    "updated_tokens = [line.strip() for line in updated_tokens]\n",
    "\n",
    "\n",
    "data['updated_tokens'] = updated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6d29ddf-7e0d-446b-9b2f-bf0f2b0641ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert list of strings to dataframe column with list of tokens on each row\n",
    "data['updated_tokens'] = data['updated_tokens'].apply(lambda x: list(tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f173208f-40c8-4053-8615-f9ac3c34accd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4158, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe of all empty token lists due to removal of additional stopwords\n",
    "empty_tokens = data[data['updated_tokens'].apply(lambda x: len(x) == 0)]\n",
    "\n",
    "empty_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfadea0c-c866-427c-b4fa-e7498d35a3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tokens</th>\n",
       "      <th>updated_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfo2hl</td>\n",
       "      <td>2021</td>\n",
       "      <td>*Cuntry roads, take me hoem*</td>\n",
       "      <td>cuntry roads hoem</td>\n",
       "      <td>3</td>\n",
       "      <td>[cuntry, road, hoem]</td>\n",
       "      <td>[road]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfou07</td>\n",
       "      <td>2021</td>\n",
       "      <td>I am single and I have not traveled to any cun...</td>\n",
       "      <td>single traveled cuntry past year</td>\n",
       "      <td>5</td>\n",
       "      <td>[single, travel, cuntry, past, year]</td>\n",
       "      <td>[single, travel, past]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfrgpe</td>\n",
       "      <td>2021</td>\n",
       "      <td>What happens when you shop at dragon mart...</td>\n",
       "      <td>happens shop dragon mart</td>\n",
       "      <td>4</td>\n",
       "      <td>[happen, shop, dragon, mart]</td>\n",
       "      <td>[shop, dragon, mart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>gthiiwi</td>\n",
       "      <td>2021</td>\n",
       "      <td>That’s just absolutely hilarious, is this in t...</td>\n",
       "      <td>absolutely hilarious springs souk</td>\n",
       "      <td>4</td>\n",
       "      <td>[absolutely, hilarious, spring, souk]</td>\n",
       "      <td>[hilarious, spring, souk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfw6yj</td>\n",
       "      <td>2021</td>\n",
       "      <td>Eugene's first day as a signwriter for Country...</td>\n",
       "      <td>eugene s day signwriter country artificial pro...</td>\n",
       "      <td>8</td>\n",
       "      <td>[eugene, s, day, signwriter, country, artifici...</td>\n",
       "      <td>[artificial, product]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99181</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f46ji</td>\n",
       "      <td>2023</td>\n",
       "      <td>Best beauty saloons in Dubai? Hello fellas, I ...</td>\n",
       "      <td>best beauty saloons dubai hello fellas moved w...</td>\n",
       "      <td>35</td>\n",
       "      <td>[good, beauty, saloon, dubai, hello, fellas, m...</td>\n",
       "      <td>[beauty, saloon, hello, wife, real, saloon, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99182</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f4uyi</td>\n",
       "      <td>2023</td>\n",
       "      <td>Found the r/dubai redditors who kept telling m...</td>\n",
       "      <td>found r dubai redditors kept telling know navi...</td>\n",
       "      <td>10</td>\n",
       "      <td>[find, r, dubai, redditor, keep, tell, know, n...</td>\n",
       "      <td>[navigate, roundabout]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99183</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f4ri3</td>\n",
       "      <td>2023</td>\n",
       "      <td>Scam ? Healthy.line My sister has a CBD debit ...</td>\n",
       "      <td>scam healthy line sister cbd debit card month ...</td>\n",
       "      <td>47</td>\n",
       "      <td>[scam, healthy, line, sister, cbd, debit, card...</td>\n",
       "      <td>[scam, healthy, line, sister, cbd, debit, card...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99184</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f4k3r</td>\n",
       "      <td>2023</td>\n",
       "      <td>Thoughts on Expo City properties? Anyone else ...</td>\n",
       "      <td>thoughts expo city properties checked expo cit...</td>\n",
       "      <td>21</td>\n",
       "      <td>[thought, expo, city, property, check, expo, c...</td>\n",
       "      <td>[expo, property, expo, sale, page, pleasant, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99185</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f8d30</td>\n",
       "      <td>2023</td>\n",
       "      <td>What to do when the neighbour parks like this?...</td>\n",
       "      <td>neighbour parks like hello dubai community guy...</td>\n",
       "      <td>19</td>\n",
       "      <td>[neighbour, park, like, hello, dubai, communit...</td>\n",
       "      <td>[neighbour, park, hello, community, meet, park...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95028 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_type       ID  year  \\\n",
       "0         comment  gtfo2hl  2021   \n",
       "2         comment  gtfou07  2021   \n",
       "3         comment  gtfrgpe  2021   \n",
       "4         comment  gthiiwi  2021   \n",
       "6         comment  gtfw6yj  2021   \n",
       "...           ...      ...   ...   \n",
       "99181  submission  14f46ji  2023   \n",
       "99182  submission  14f4uyi  2023   \n",
       "99183  submission  14f4ri3  2023   \n",
       "99184  submission  14f4k3r  2023   \n",
       "99185  submission  14f8d30  2023   \n",
       "\n",
       "                                               long_text  \\\n",
       "0                           *Cuntry roads, take me hoem*   \n",
       "2      I am single and I have not traveled to any cun...   \n",
       "3           What happens when you shop at dragon mart...   \n",
       "4      That’s just absolutely hilarious, is this in t...   \n",
       "6      Eugene's first day as a signwriter for Country...   \n",
       "...                                                  ...   \n",
       "99181  Best beauty saloons in Dubai? Hello fellas, I ...   \n",
       "99182  Found the r/dubai redditors who kept telling m...   \n",
       "99183  Scam ? Healthy.line My sister has a CBD debit ...   \n",
       "99184  Thoughts on Expo City properties? Anyone else ...   \n",
       "99185  What to do when the neighbour parks like this?...   \n",
       "\n",
       "                                              clean_text  word_count  \\\n",
       "0                                      cuntry roads hoem           3   \n",
       "2                       single traveled cuntry past year           5   \n",
       "3                               happens shop dragon mart           4   \n",
       "4                      absolutely hilarious springs souk           4   \n",
       "6      eugene s day signwriter country artificial pro...           8   \n",
       "...                                                  ...         ...   \n",
       "99181  best beauty saloons dubai hello fellas moved w...          35   \n",
       "99182  found r dubai redditors kept telling know navi...          10   \n",
       "99183  scam healthy line sister cbd debit card month ...          47   \n",
       "99184  thoughts expo city properties checked expo cit...          21   \n",
       "99185  neighbour parks like hello dubai community guy...          19   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0                                   [cuntry, road, hoem]   \n",
       "2                   [single, travel, cuntry, past, year]   \n",
       "3                           [happen, shop, dragon, mart]   \n",
       "4                  [absolutely, hilarious, spring, souk]   \n",
       "6      [eugene, s, day, signwriter, country, artifici...   \n",
       "...                                                  ...   \n",
       "99181  [good, beauty, saloon, dubai, hello, fellas, m...   \n",
       "99182  [find, r, dubai, redditor, keep, tell, know, n...   \n",
       "99183  [scam, healthy, line, sister, cbd, debit, card...   \n",
       "99184  [thought, expo, city, property, check, expo, c...   \n",
       "99185  [neighbour, park, like, hello, dubai, communit...   \n",
       "\n",
       "                                          updated_tokens  \n",
       "0                                                 [road]  \n",
       "2                                 [single, travel, past]  \n",
       "3                                   [shop, dragon, mart]  \n",
       "4                              [hilarious, spring, souk]  \n",
       "6                                  [artificial, product]  \n",
       "...                                                  ...  \n",
       "99181  [beauty, saloon, hello, wife, real, saloon, re...  \n",
       "99182                             [navigate, roundabout]  \n",
       "99183  [scam, healthy, line, sister, cbd, debit, card...  \n",
       "99184  [expo, property, expo, sale, page, pleasant, p...  \n",
       "99185  [neighbour, park, hello, community, meet, park...  \n",
       "\n",
       "[95028 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adjust corpus to remvoe rows with empty token lists\n",
    "row_id = empty_tokens['ID'] #id of rows with empty token list\n",
    "\n",
    "updated_data = data[~data['ID'].isin(row_id)]\n",
    "updated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abdb0075-efde-409f-9bb3-862a74eaa960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save filtered corpus to data\n",
    "\n",
    "filename = 'Data/filtered_corpus.csv'\n",
    "\n",
    "def export_csv():\n",
    "    '''\n",
    "    export filtered data to CSV\n",
    "    '''\n",
    "    updated_data.to_csv(filename, index_label = 'index', quoting = csv.QUOTE_ALL, header = True)\n",
    "\n",
    "export_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df64e2f-3ec4-4050-a57b-612dd270b8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "projectenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
