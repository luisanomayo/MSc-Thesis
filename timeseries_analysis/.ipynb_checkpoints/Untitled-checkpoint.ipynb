{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e27aa65f-bc9e-4f8b-958f-c60882fb2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import Phrases\n",
    "from gensim.models import LdaModel, CoherenceModel, LdaMulticore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a17cbfe-02dc-40e3-8132-0d6863083f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>date_created</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfou07</td>\n",
       "      <td>2021-04-05 13:13:23</td>\n",
       "      <td>2021</td>\n",
       "      <td>I am single and I have not traveled to any cun...</td>\n",
       "      <td>single travel past</td>\n",
       "      <td>[single, travel, past]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfrgpe</td>\n",
       "      <td>2021-04-05 13:56:09</td>\n",
       "      <td>2021</td>\n",
       "      <td>What happens when you shop at dragon mart...</td>\n",
       "      <td>shop dragon mart</td>\n",
       "      <td>[shop, dragon, mart]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>gthiiwi</td>\n",
       "      <td>2021-04-05 23:18:56</td>\n",
       "      <td>2021</td>\n",
       "      <td>That’s just absolutely hilarious, is this in t...</td>\n",
       "      <td>hilarious spring souk</td>\n",
       "      <td>[hilarious, spring, souk]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtgfl4c</td>\n",
       "      <td>2021-04-05 18:21:42</td>\n",
       "      <td>2021</td>\n",
       "      <td>Is reel cinema and roxy part of emaar?</td>\n",
       "      <td>reel cinema roxy emaar</td>\n",
       "      <td>[reel, cinema, roxy, emaar]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>gth5wdv</td>\n",
       "      <td>2021-04-05 21:42:41</td>\n",
       "      <td>2021</td>\n",
       "      <td>An innocent redditor here...can someone pls ex...</td>\n",
       "      <td>innocent pls explain everyday</td>\n",
       "      <td>[innocent, pls, explain, everyday]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_type       ID         date_created  year  \\\n",
       "0   comment  gtfou07  2021-04-05 13:13:23  2021   \n",
       "1   comment  gtfrgpe  2021-04-05 13:56:09  2021   \n",
       "2   comment  gthiiwi  2021-04-05 23:18:56  2021   \n",
       "3   comment  gtgfl4c  2021-04-05 18:21:42  2021   \n",
       "4   comment  gth5wdv  2021-04-05 21:42:41  2021   \n",
       "\n",
       "                                           long_text  \\\n",
       "0  I am single and I have not traveled to any cun...   \n",
       "1       What happens when you shop at dragon mart...   \n",
       "2  That’s just absolutely hilarious, is this in t...   \n",
       "3             Is reel cinema and roxy part of emaar?   \n",
       "4  An innocent redditor here...can someone pls ex...   \n",
       "\n",
       "                      clean_text                              tokens  \\\n",
       "0             single travel past              [single, travel, past]   \n",
       "1               shop dragon mart                [shop, dragon, mart]   \n",
       "2          hilarious spring souk           [hilarious, spring, souk]   \n",
       "3         reel cinema roxy emaar         [reel, cinema, roxy, emaar]   \n",
       "4  innocent pls explain everyday  [innocent, pls, explain, everyday]   \n",
       "\n",
       "   word_count  \n",
       "0           3  \n",
       "1           3  \n",
       "2           3  \n",
       "3           4  \n",
       "4           4  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import cleaned data\n",
    "\n",
    "def list_converter(text):\n",
    "    #to revert list->str conversion from pd.read_csv\n",
    "    return ast.literal_eval(text)\n",
    "\n",
    "\n",
    "data = pd.read_csv('../Data/training_data.csv', converters ={'tokens':list_converter})\n",
    "data = data.drop(columns = ['index'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a16b1741-7d08-444b-ab6d-e1833fdb406a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extract submissions\n",
    "\n",
    "#submissions = data[data.text_type == 'submission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01c4440d-850a-4fce-a0c4-a033b8d23ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#submissions ID\n",
    "#sub_id = submissions['ID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6d051d1-c77e-4b8a-ae36-848abe292d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save sub_ids\n",
    "\n",
    "with open ('sub_ids', 'wb') as file:\n",
    "    pickle.dump(sub_id, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c5e81-3f02-470e-9e95-da656641c119",
   "metadata": {},
   "source": [
    "## **LOAD MODEL AND CORPUS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c74c4cfb-08a9-4a42-85c2-af3eb7f2688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LdaModel.load(\"../topic_modelling/lda_model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "372a0e61-f775-44d1-9d15-bbd717de497c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 5000\n",
      "Number of documents: 65987\n"
     ]
    }
   ],
   "source": [
    "#convert df['tokens'] to list of strings for bag-of-words model\n",
    "docs = data['tokens'].tolist()\n",
    "\n",
    "#from gensim bag of words documentation page\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = corpora.Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
    "\n",
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b554957-7c55-4145-86ed-2e9ff1b7764b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.026*\"police\" + 0.015*\"building\" + 0.014*\"family\" + 0.012*\"parent\" + 0.012*\"wife\" + 0.011*\"area\" + 0.011*\"parking\" + 0.011*\"metro\" + 0.011*\"child\" + 0.010*\"station\"'),\n",
       " (1,\n",
       "  '0.039*\"visa\" + 0.021*\"card\" + 0.014*\"apply\" + 0.013*\"bank\" + 0.013*\"visit\" + 0.013*\"travel\" + 0.012*\"website\" + 0.010*\"book\" + 0.010*\"plan\" + 0.010*\"cancel\"'),\n",
       " (2,\n",
       "  '0.017*\"price\" + 0.017*\"buy\" + 0.016*\"salary\" + 0.015*\"cost\" + 0.014*\"rent\" + 0.012*\"property\" + 0.012*\"market\" + 0.010*\"aed\" + 0.010*\"sell\" + 0.009*\"offer\"'),\n",
       " (3,\n",
       "  '0.020*\"law\" + 0.018*\"government\" + 0.016*\"local\" + 0.014*\"muslim\" + 0.011*\"culture\" + 0.011*\"arab\" + 0.010*\"rule\" + 0.009*\"community\" + 0.009*\"expat\" + 0.008*\"citizenship\"'),\n",
       " (4,\n",
       "  '0.036*\"covid\" + 0.030*\"test\" + 0.024*\"fine\" + 0.013*\"vaccine\" + 0.012*\"worker\" + 0.012*\"stop\" + 0.012*\"mask\" + 0.010*\"medical\" + 0.010*\"hospital\" + 0.010*\"pandemic\"'),\n",
       " (5,\n",
       "  '0.036*\"food\" + 0.027*\"order\" + 0.024*\"buy\" + 0.022*\"restaurant\" + 0.022*\"tip\" + 0.022*\"service\" + 0.021*\"delivery\" + 0.013*\"noon\" + 0.011*\"amazon\" + 0.011*\"customer\"'),\n",
       " (6,\n",
       "  '0.053*\"drive\" + 0.035*\"road\" + 0.028*\"lane\" + 0.017*\"fast\" + 0.017*\"speed\" + 0.015*\"pass\" + 0.015*\"light\" + 0.014*\"traffic\" + 0.012*\"driver\" + 0.011*\"vehicle\"'),\n",
       " (7,\n",
       "  '0.023*\"water\" + 0.014*\"beach\" + 0.013*\"movie\" + 0.013*\"summer\" + 0.013*\"cat\" + 0.013*\"ban\" + 0.011*\"hot\" + 0.011*\"taste\" + 0.010*\"chicken\" + 0.010*\"dog\"'),\n",
       " (8,\n",
       "  '0.015*\"indian\" + 0.015*\"arabic\" + 0.012*\"middle\" + 0.011*\"passport\" + 0.010*\"school\" + 0.010*\"university\" + 0.009*\"language\" + 0.008*\"canada\" + 0.008*\"nationality\" + 0.008*\"europe\"'),\n",
       " (9,\n",
       "  '0.019*\"night\" + 0.018*\"mall\" + 0.016*\"walk\" + 0.014*\"hotel\" + 0.011*\"room\" + 0.011*\"area\" + 0.010*\"drink\" + 0.008*\"visit\" + 0.008*\"marina\" + 0.008*\"social\"')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7dc70162-24b5-4428-b73d-939dcdee9ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic label\n",
    "\n",
    "topic_label ={\n",
    "    0: \"infrastructure\",\n",
    "    1: \"travel\",\n",
    "    2: \"accomodation and rental\",\n",
    "    3: \"locals and culture\",\n",
    "    4: \"covid\",\n",
    "    5: \"food and dining\",\n",
    "    6: \"driving and road safety\",\n",
    "    7: \"weather and outdoors\",\n",
    "    8: \"education and educational facilities\",\n",
    "    9: \"entertainment and recreation\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bbe2174f-5d87-4a05-a411-c108750aba45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[police, building, family, parent, wife, area,...</td>\n",
       "      <td>infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[visa, card, apply, bank, visit, travel, websi...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[price, buy, salary, cost, rent, property, mar...</td>\n",
       "      <td>accomodation and rental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[law, government, local, muslim, culture, arab...</td>\n",
       "      <td>locals and culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[covid, test, fine, vaccine, worker, stop, mas...</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[food, order, buy, restaurant, tip, service, d...</td>\n",
       "      <td>food and dining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[drive, road, lane, fast, speed, pass, light, ...</td>\n",
       "      <td>driving and road safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[water, beach, movie, summer, cat, ban, hot, t...</td>\n",
       "      <td>weather and outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[indian, arabic, middle, passport, school, uni...</td>\n",
       "      <td>education and educational facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[night, mall, walk, hotel, room, area, drink, ...</td>\n",
       "      <td>entertainment and recreation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                                              words  \\\n",
       "0      0  [police, building, family, parent, wife, area,...   \n",
       "1      1  [visa, card, apply, bank, visit, travel, websi...   \n",
       "2      2  [price, buy, salary, cost, rent, property, mar...   \n",
       "3      3  [law, government, local, muslim, culture, arab...   \n",
       "4      4  [covid, test, fine, vaccine, worker, stop, mas...   \n",
       "5      5  [food, order, buy, restaurant, tip, service, d...   \n",
       "6      6  [drive, road, lane, fast, speed, pass, light, ...   \n",
       "7      7  [water, beach, movie, summer, cat, ban, hot, t...   \n",
       "8      8  [indian, arabic, middle, passport, school, uni...   \n",
       "9      9  [night, mall, walk, hotel, room, area, drink, ...   \n",
       "\n",
       "                                  label  \n",
       "0                        infrastructure  \n",
       "1                                travel  \n",
       "2               accomodation and rental  \n",
       "3                    locals and culture  \n",
       "4                                 covid  \n",
       "5                       food and dining  \n",
       "6               driving and road safety  \n",
       "7                  weather and outdoors  \n",
       "8  education and educational facilities  \n",
       "9          entertainment and recreation  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset of topcis and topic representation\n",
    "num_topics = model.num_topics\n",
    "\n",
    "topics_words = []\n",
    "\n",
    "for topic in range(num_topics):\n",
    "    topic_words = model.show_topic(topic, topn = 10)\n",
    "    words = [word[0] for word in topic_words]\n",
    "    topics_words.append({\"topic\": topic, \"words\": words, \"label\":topic_label[topic]})\n",
    "    \n",
    "\n",
    "#create a dataframe\n",
    "topics_df = pd.DataFrame(topics_words)\n",
    "\n",
    "topics_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e89b927-9356-496f-a6b9-1397a805b70d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include column for most probable topic for each entry\n",
    "\n",
    "top_topic_per_document = []\n",
    "\n",
    "for doc in corpus:\n",
    "    topics = model.get_document_topics(doc)\n",
    "    top_topic = sorted(topics, key=lambda x: x[1], reverse = True)[0][0]\n",
    "    top_topic_per_document.append(top_topic)\n",
    "    \n",
    "#add column to data dataframe for the selected topic\n",
    "data['top_topic'] = top_topic_per_document    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d909e47-32fa-4c34-b3cb-e344159b7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge topic label data dataframes\n",
    "\n",
    "full_df = data.merge(topics_df, merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "662bce0c-0071-4970-a28b-8986d7a7347c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>date_created</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>top_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62813</th>\n",
       "      <td>submission</td>\n",
       "      <td>iw964e</td>\n",
       "      <td>2020-09-20 11:10:32</td>\n",
       "      <td>2020</td>\n",
       "      <td>Here’s a time-lapse I did of the golden sunset...</td>\n",
       "      <td>lapse golden sunset pass burj khalifa</td>\n",
       "      <td>[lapse, golden, sunset, pass, burj, khalifa, b...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62814</th>\n",
       "      <td>submission</td>\n",
       "      <td>r38z4m</td>\n",
       "      <td>2021-11-27 12:14:59</td>\n",
       "      <td>2021</td>\n",
       "      <td>Helped find a tourist their lost wedding ring ...</td>\n",
       "      <td>helped tourist lost wedding ring jbr beach met...</td>\n",
       "      <td>[helped, tourist, lost, wedding, ring, jbr, be...</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62815</th>\n",
       "      <td>submission</td>\n",
       "      <td>sl3qco</td>\n",
       "      <td>2022-02-05 14:15:16</td>\n",
       "      <td>2022</td>\n",
       "      <td>My colleagues and I drove from Dubai this morn...</td>\n",
       "      <td>colleague drive morning pick garbage beach ajm...</td>\n",
       "      <td>[colleague, drive, morning, pick, garbage, bea...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62816</th>\n",
       "      <td>submission</td>\n",
       "      <td>12hxnxe</td>\n",
       "      <td>2023-04-11 01:53:28</td>\n",
       "      <td>2023</td>\n",
       "      <td>Update on Karen case I posted a year ago about...</td>\n",
       "      <td>karen horrible karen community court instance ...</td>\n",
       "      <td>[karen, horrible, karen, community, court, ins...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62817</th>\n",
       "      <td>submission</td>\n",
       "      <td>khzit1</td>\n",
       "      <td>2020-12-22 10:05:58</td>\n",
       "      <td>2020</td>\n",
       "      <td>Fresh supply just entered from Oman. We safe.</td>\n",
       "      <td>fresh supply oman safe</td>\n",
       "      <td>[fresh, supply, oman, safe]</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65982</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f49ta</td>\n",
       "      <td>2023-06-21 14:45:45</td>\n",
       "      <td>2023</td>\n",
       "      <td>Legal advice needed. Would highly appreciate i...</td>\n",
       "      <td>legal highly legal highly private involved par...</td>\n",
       "      <td>[legal, highly, legal, highly, private, involv...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65983</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f46ji</td>\n",
       "      <td>2023-06-21 14:40:54</td>\n",
       "      <td>2023</td>\n",
       "      <td>Best beauty saloons in Dubai? Hello fellas, I ...</td>\n",
       "      <td>beauty saloon fella wife real saloon beauty sa...</td>\n",
       "      <td>[beauty, saloon, fella, wife, real, saloon, be...</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65984</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f4ri3</td>\n",
       "      <td>2023-06-21 15:10:25</td>\n",
       "      <td>2023</td>\n",
       "      <td>Scam ? Healthy.line My sister has a CBD debit ...</td>\n",
       "      <td>scam healthy line sister cbd debit card april ...</td>\n",
       "      <td>[scam, healthy, line, sister, cbd, debit, card...</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65985</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f4k3r</td>\n",
       "      <td>2023-06-21 15:00:34</td>\n",
       "      <td>2023</td>\n",
       "      <td>Thoughts on Expo City properties? Anyone else ...</td>\n",
       "      <td>expo property expo sale pleasant price locate ...</td>\n",
       "      <td>[expo, property, expo, sale, pleasant, price, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65986</th>\n",
       "      <td>submission</td>\n",
       "      <td>14f8d30</td>\n",
       "      <td>2023-06-21 17:53:14</td>\n",
       "      <td>2023</td>\n",
       "      <td>What to do when the neighbour parks like this?...</td>\n",
       "      <td>neighbour park community meet parking professi...</td>\n",
       "      <td>[neighbour, park, community, meet, parking, pr...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3174 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_type       ID         date_created  year  \\\n",
       "62813  submission   iw964e  2020-09-20 11:10:32  2020   \n",
       "62814  submission   r38z4m  2021-11-27 12:14:59  2021   \n",
       "62815  submission   sl3qco  2022-02-05 14:15:16  2022   \n",
       "62816  submission  12hxnxe  2023-04-11 01:53:28  2023   \n",
       "62817  submission   khzit1  2020-12-22 10:05:58  2020   \n",
       "...           ...      ...                  ...   ...   \n",
       "65982  submission  14f49ta  2023-06-21 14:45:45  2023   \n",
       "65983  submission  14f46ji  2023-06-21 14:40:54  2023   \n",
       "65984  submission  14f4ri3  2023-06-21 15:10:25  2023   \n",
       "65985  submission  14f4k3r  2023-06-21 15:00:34  2023   \n",
       "65986  submission  14f8d30  2023-06-21 17:53:14  2023   \n",
       "\n",
       "                                               long_text  \\\n",
       "62813  Here’s a time-lapse I did of the golden sunset...   \n",
       "62814  Helped find a tourist their lost wedding ring ...   \n",
       "62815  My colleagues and I drove from Dubai this morn...   \n",
       "62816  Update on Karen case I posted a year ago about...   \n",
       "62817     Fresh supply just entered from Oman. We safe.    \n",
       "...                                                  ...   \n",
       "65982  Legal advice needed. Would highly appreciate i...   \n",
       "65983  Best beauty saloons in Dubai? Hello fellas, I ...   \n",
       "65984  Scam ? Healthy.line My sister has a CBD debit ...   \n",
       "65985  Thoughts on Expo City properties? Anyone else ...   \n",
       "65986  What to do when the neighbour parks like this?...   \n",
       "\n",
       "                                              clean_text  \\\n",
       "62813              lapse golden sunset pass burj khalifa   \n",
       "62814  helped tourist lost wedding ring jbr beach met...   \n",
       "62815  colleague drive morning pick garbage beach ajm...   \n",
       "62816  karen horrible karen community court instance ...   \n",
       "62817                             fresh supply oman safe   \n",
       "...                                                  ...   \n",
       "65982  legal highly legal highly private involved par...   \n",
       "65983  beauty saloon fella wife real saloon beauty sa...   \n",
       "65984  scam healthy line sister cbd debit card april ...   \n",
       "65985  expo property expo sale pleasant price locate ...   \n",
       "65986  neighbour park community meet parking professi...   \n",
       "\n",
       "                                                  tokens  word_count  \\\n",
       "62813  [lapse, golden, sunset, pass, burj, khalifa, b...           6   \n",
       "62814  [helped, tourist, lost, wedding, ring, jbr, be...          12   \n",
       "62815  [colleague, drive, morning, pick, garbage, bea...          11   \n",
       "62816  [karen, horrible, karen, community, court, ins...          40   \n",
       "62817                        [fresh, supply, oman, safe]           4   \n",
       "...                                                  ...         ...   \n",
       "65982  [legal, highly, legal, highly, private, involv...          10   \n",
       "65983  [beauty, saloon, fella, wife, real, saloon, be...          17   \n",
       "65984  [scam, healthy, line, sister, cbd, debit, card...          35   \n",
       "65985  [expo, property, expo, sale, pleasant, price, ...           9   \n",
       "65986  [neighbour, park, community, meet, parking, pr...           8   \n",
       "\n",
       "       top_topic  \n",
       "62813          5  \n",
       "62814          7  \n",
       "62815          7  \n",
       "62816          0  \n",
       "62817          7  \n",
       "...          ...  \n",
       "65982          2  \n",
       "65983          8  \n",
       "65984          1  \n",
       "65985          2  \n",
       "65986          0  \n",
       "\n",
       "[3174 rows x 9 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#topics assigned to posts\n",
    "submissions = data[data.text_type == 'submission']\n",
    "submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b5643-438c-429a-afc8-2430890a1aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "projectenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
