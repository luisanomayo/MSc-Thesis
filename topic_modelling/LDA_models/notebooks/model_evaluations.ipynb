{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218c120d-929d-459d-a504-66ecb140f636",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h1><b>Topic Modelling with LDA: Evaluation</b></h1>\n",
    "    <p style = \"color: black\"> Using LDA model on pre-processed data. Stop word removal during pre-processing is limited to common english stop words, top 100 most common words, and words occuring less than 10 times.<br>Any further stop word removal will be done when creating bag of words with the gensim library \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9413769-204d-4f78-8ed0-492d1b1241ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>I. Setting Up Environment</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f558492-64cf-4cb4-b59e-3832e2587055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data transformation libraries\n",
    "import pandas as pd\n",
    "from pandas import option_context\n",
    "import numpy as np\n",
    "import ast\n",
    "import csv\n",
    "\n",
    "#NLP specific libraries\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#topic modelling libraries\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, CoherenceModel, LdaMulticore\n",
    "\n",
    "\n",
    "#for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "#others\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bdf6c5c-3d5e-41d5-beb9-442ffffb2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed so that code output is deterministic\n",
    "random.seed(200)  # Set the seed for Python's random module\n",
    "np.random.seed(200)  # Set the seed for NumPy's random module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac14eb5-b63b-46de-ae55-5fb6589e31e0",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>II. Import Data</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b0ba03-939b-4f3a-857b-ede3e330fa64",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>a. Import preprocessed data</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01f4305-54c2-4988-a62e-c2e960f8a295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>date_created</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d18gk</td>\n",
       "      <td>2012-09-25 07:57:13</td>\n",
       "      <td>2012</td>\n",
       "      <td>Yet i stared at the picture for a good 45 seco...</td>\n",
       "      <td>stare picture second miss</td>\n",
       "      <td>[stare, picture, second, miss]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d2fss</td>\n",
       "      <td>2012-09-25 09:13:23</td>\n",
       "      <td>2012</td>\n",
       "      <td>[FYSR] = from your sister subreddit.\\n\\nIMO, i...</td>\n",
       "      <td>sister subreddit mildly interesting chance eve...</td>\n",
       "      <td>[sister, subreddit, mildly, interesting, chanc...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d46es</td>\n",
       "      <td>2012-09-25 12:32:08</td>\n",
       "      <td>2012</td>\n",
       "      <td>common give prince william harry a break he ju...</td>\n",
       "      <td>common prince harry break</td>\n",
       "      <td>[common, prince, harry, break]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>submission</td>\n",
       "      <td>1sur9h</td>\n",
       "      <td>2013-12-14 11:02:08</td>\n",
       "      <td>2013</td>\n",
       "      <td>Took this image of the Burj Khalifa from Souk ...</td>\n",
       "      <td>image burj khalifa souk bahar yesterday build ...</td>\n",
       "      <td>[image, burj, khalifa, souk, bahar, yesterday,...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>ce1gf68</td>\n",
       "      <td>2013-12-14 12:07:24</td>\n",
       "      <td>2013</td>\n",
       "      <td>Sorry pal, but you took an artistically not-so...</td>\n",
       "      <td>sorry impressive photo landmark resident karma...</td>\n",
       "      <td>[sorry, impressive, photo, landmark, resident,...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_type       ID         date_created  year  \\\n",
       "0     comment  c6d18gk  2012-09-25 07:57:13  2012   \n",
       "1     comment  c6d2fss  2012-09-25 09:13:23  2012   \n",
       "2     comment  c6d46es  2012-09-25 12:32:08  2012   \n",
       "3  submission   1sur9h  2013-12-14 11:02:08  2013   \n",
       "4     comment  ce1gf68  2013-12-14 12:07:24  2013   \n",
       "\n",
       "                                           long_text  \\\n",
       "0  Yet i stared at the picture for a good 45 seco...   \n",
       "1  [FYSR] = from your sister subreddit.\\n\\nIMO, i...   \n",
       "2  common give prince william harry a break he ju...   \n",
       "3  Took this image of the Burj Khalifa from Souk ...   \n",
       "4  Sorry pal, but you took an artistically not-so...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                          stare picture second miss   \n",
       "1  sister subreddit mildly interesting chance eve...   \n",
       "2                          common prince harry break   \n",
       "3  image burj khalifa souk bahar yesterday build ...   \n",
       "4  sorry impressive photo landmark resident karma...   \n",
       "\n",
       "                                              tokens  word_count  \n",
       "0                     [stare, picture, second, miss]           4  \n",
       "1  [sister, subreddit, mildly, interesting, chanc...          18  \n",
       "2                     [common, prince, harry, break]           4  \n",
       "3  [image, burj, khalifa, souk, bahar, yesterday,...          11  \n",
       "4  [sorry, impressive, photo, landmark, resident,...           8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import training_data\n",
    "\n",
    "def list_converter(text):\n",
    "    #to revert list->str conversion from pd.read_csv\n",
    "    return ast.literal_eval(text)\n",
    "\n",
    "\n",
    "data = pd.read_csv('../../../Data/lda_train.csv', converters ={'tokens':list_converter})\n",
    "data = data.drop(columns = ['index'])\n",
    "data.sort_values(by='date_created', inplace = True, ignore_index = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "350b4c13-7c16-416f-95c7-447a892091c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61376 entries, 0 to 61375\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   text_type     61376 non-null  object\n",
      " 1   ID            61376 non-null  object\n",
      " 2   date_created  61376 non-null  object\n",
      " 3   year          61376 non-null  int64 \n",
      " 4   long_text     61376 non-null  object\n",
      " 5   clean_text    61376 non-null  object\n",
      " 6   tokens        61376 non-null  object\n",
      " 7   word_count    61376 non-null  int64 \n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b44e9-1dc2-451f-b23a-b877d4a05529",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>b. Import Bag-of-Words</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdeabd3d-4f58-4aa6-8792-6ba51d801b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data['tokens'].tolist()\n",
    "# Create bigrams - code from gensim documentation page\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)\n",
    "            \n",
    "dictionary = corpora.Dictionary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab49f2f-43ea-41b9-921a-57b4b389e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/bow_corpus.pkl\", \"rb\") as f:\n",
    "    bow = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92931959-a8bf-49e4-85b6-216e043713cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1), (3, 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5963f8a-c023-458c-a6f5-2c155a8a5637",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>c. Import Word2Vec Model</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f857bc4-d225-4775-bf06-bcdd40d61d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('../models/w2v_model_lda_bigrams.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c6a6e7-58d4-4b48-9b48-59b2216b2199",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>III. LDA Model Visual Evaluation</b></h2>\n",
    "</span>\n",
    "<p>A review of the top 10 words in each topic to determine the following:\n",
    "    <ul>\n",
    "    <li>Do they make sense?</li>\n",
    "    <li>can the topic be given a label?</li>\n",
    "    <li>Using a sample of the submissions in the training data, determine if the topics are accurate\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5377f02b-904b-4d97-8685-d4c935cb0d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#functions for evaluating the models\n",
    "#function to compute coherence, diversity and perplexity metrics\n",
    "def eval_metrics (lda_model, docs, dictionary, num_topics, corpus, top_n = 10):\n",
    "    #Compute c_v score\n",
    "    c_v = CoherenceModel(model=lda_model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "    cv_lda = c_v.get_coherence()\n",
    "    \n",
    "    # Compute u_mass score\n",
    "    u_mass = CoherenceModel(model=lda_model, texts=docs, dictionary=dictionary, coherence='u_mass')\n",
    "    umass_lda = u_mass.get_coherence()\n",
    "    \n",
    "    # Compute c_npmi score\n",
    "    c_npmi = CoherenceModel(model=lda_model, texts=docs, dictionary=dictionary, coherence='c_npmi')\n",
    "    cnpmi_lda = c_npmi.get_coherence()\n",
    "    \n",
    "    # Compute perplexity\n",
    "    perplexity = lda_model.log_perplexity(corpus)\n",
    "    \n",
    "    # Compute topic diversity\n",
    "    top_words = [word for topic_id in range(num_topics) for word, _ in lda_model.show_topic(topic_id, topn=top_n)]\n",
    "    diversity = len(set(top_words)) / (num_topics * top_n)\n",
    "    \n",
    "    print(f\"For {num_topics} topics:\\nCoherence(c_v) = {cv_lda},\\nCoherence(c_npmi) = {cnpmi_lda},\\nCoherence(u_mass) = {umass_lda},\\nPerplexity = {perplexity},\\nTopic Diversity = {diversity}\\n\")\n",
    "    \n",
    "    #return cv_lda, umass_lda, cnpmi_lda, perplexity, diversity\n",
    "\n",
    "#function to check average word similarities for the topics \n",
    "def average_similarity(lda_model, num_topics, w2v_model, top_n=10):\n",
    "    #extract top 10 words for each topic\n",
    "    top_words_per_topic =[] \n",
    "    for topic_id in range(num_topics):\n",
    "        top_words = lda_model.show_topic(topic_id, topn=top_n)\n",
    "        top_words = [word for word, _ in top_words]\n",
    "        top_words_per_topic.append(top_words)\n",
    "        \n",
    "    # 2. Compute pairwise similarities for each topic\n",
    "    average_similarities = []\n",
    "    for top_words in top_words_per_topic:\n",
    "        total_similarity = 0\n",
    "        count = 0\n",
    "        for i in range(len(top_words)):\n",
    "            for j in range(i+1, len(top_words)):  # Compare each word with the words after it\n",
    "                if top_words[i] in w2v_model.wv and top_words[j] in w2v_model.wv:\n",
    "                    similarity = w2v_model.wv.similarity(top_words[i], top_words[j])\n",
    "                    total_similarity += similarity\n",
    "                    count += 1\n",
    "        average_similarity = total_similarity / count if count != 0 else 0\n",
    "        average_similarities.append(average_similarity)\n",
    "    #print average similarities for each topic\n",
    "    for idx, avg_sim in enumerate(average_similarities):\n",
    "        print(f\"Average similarity for topic {idx}: {avg_sim:.4f}\")\n",
    "        \n",
    "    #return average_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cfde49-65c1-4ceb-9f21-4e19468b0058",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>a. model 1: 5 topics</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60667593-2a2e-4411-9439-fd75f708f807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_1 = LdaModel.load('../models/model_1_5tpcs/lda_model_1_5tpcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb772512-6caa-4ed6-bf33-daad2600f49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 5 topics:\n",
      "Coherence(c_v) = 0.6049680135364921,\n",
      "Coherence(c_npmi) = 0.01809764921147028,\n",
      "Coherence(u_mass) = -3.6348576844708056,\n",
      "Perplexity = -8.133242504850717,\n",
      "Topic Diversity = 1.0\n",
      "\n",
      "Average similarity for topic 0: 0.4982\n",
      "Average similarity for topic 1: 0.4522\n",
      "Average similarity for topic 2: 0.2859\n",
      "Average similarity for topic 3: 0.4426\n",
      "Average similarity for topic 4: 0.5138\n"
     ]
    }
   ],
   "source": [
    "#quantitative evaluation\n",
    "eval_metrics (lda_model = model_1,docs = docs,\n",
    "              dictionary = dictionary, num_topics = model_1.num_topics, \n",
    "               corpus = bow, top_n = 10)\n",
    "\n",
    "average_similarity(lda_model = model_1, num_topics = model_1.num_topics, \n",
    "                   w2v_model = w2v_model, top_n=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e337866c-e892-47d3-96db-82353ed6f23c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"report\" + 0.012*\"area\" + 0.011*\"car\" + 0.011*\"close\" + 0.010*\"fast\" + 0.009*\"speed\" + 0.008*\"metro\" + 0.008*\"traffic\" + 0.008*\"park\" + 0.008*\"turn\"'),\n",
       " (1,\n",
       "  '0.010*\"bank\" + 0.009*\"rent\" + 0.007*\"sell\" + 0.007*\"send\" + 0.007*\"week\" + 0.007*\"property\" + 0.007*\"cheap\" + 0.006*\"order\" + 0.006*\"option\" + 0.006*\"charge\"'),\n",
       " (2,\n",
       "  '0.010*\"mall\" + 0.010*\"walk\" + 0.008*\"reddit\" + 0.007*\"video\" + 0.007*\"stuff\" + 0.006*\"outside\" + 0.006*\"night\" + 0.006*\"tip\" + 0.006*\"visit\" + 0.006*\"social\"'),\n",
       " (3,\n",
       "  '0.007*\"kid\" + 0.006*\"care\" + 0.006*\"hard\" + 0.006*\"speak\" + 0.006*\"sorry\" + 0.006*\"culture\" + 0.006*\"learn\" + 0.006*\"situation\" + 0.006*\"school\" + 0.005*\"believe\"'),\n",
       " (4,\n",
       "  '0.007*\"passport\" + 0.006*\"allow\" + 0.006*\"government\" + 0.006*\"apply\" + 0.006*\"travel\" + 0.005*\"base\" + 0.005*\"rule\" + 0.005*\"employee\" + 0.005*\"india\" + 0.005*\"job\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.print_topics(num_topics = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5812a5b9-2b2f-4412-a43e-d207831695d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[report, area, car, close, fast, speed, metro, traffic, park, turn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[bank, rent, sell, send, week, property, cheap, order, option, charge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mall, walk, reddit, video, stuff, outside, night, tip, visit, social]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[kid, care, hard, speak, sorry, culture, learn, situation, school, believe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[passport, allow, government, apply, travel, base, rule, employee, india, job]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                words\n",
       "topic                                                                                \n",
       "0                 [report, area, car, close, fast, speed, metro, traffic, park, turn]\n",
       "1              [bank, rent, sell, send, week, property, cheap, order, option, charge]\n",
       "2              [mall, walk, reddit, video, stuff, outside, night, tip, visit, social]\n",
       "3         [kid, care, hard, speak, sorry, culture, learn, situation, school, believe]\n",
       "4      [passport, allow, government, apply, travel, base, rule, employee, india, job]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset of topcis and topic representation\n",
    "num_topics = model_1.num_topics\n",
    "\n",
    "topics_words = []\n",
    "\n",
    "for topic in range(num_topics):\n",
    "    topic_words = model_1.show_topic(topic, topn = 10)\n",
    "    words = [word[0] for word in topic_words]\n",
    "    topics_words.append({\"topic\": topic, \"words\": words})\n",
    "    \n",
    "\n",
    "#create a dataframe\n",
    "model_1_topics_df = pd.DataFrame(topics_words)\n",
    "model_1_topics_df.set_index('topic', inplace =True)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(model_1_topics_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613e581-ca4a-4a0c-a4b0-2e9aa6490bc5",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>topic 0: <em>'car', 'fast', 'speed', 'park', 'turn', 'traffic'</em> --> <em><b>urban_mobility.traffic_regulations</b></em>.\n",
    "    That means of the top 10 words, 6 relate to the same topic.</li><br>\n",
    "    <li>topic 1: <em> 'rent', 'property','sell' </em> --> <em><b>real_estate_housing</b></em>. However, the terms <em> 'sell', 'cheap', 'order'</em> --> <em><b>shopping_services</b></em>. Also, <em> 'bank', 'charge', 'send'</em> --><em><b>banking_financial_services</b></em> This topic contains three sub-topics.</li><br>\n",
    "    <li>topic 2: <em>'mall', 'walk', 'outside', 'night', 'visit',</em>label --> <em><b>recreation</b></em>, but also contains terms (<em>'reddit', 'video', 'social'</em>) related to <em><b>communication_social_media</b></em>.</li><br>\n",
    "    <li>topic 3: <em>'kid','care', 'hard',' learn', 'school'</em>, label --> <em><b>education</b></em></li><br>\n",
    "    <li>topic 4: <em>'passport', 'travel' </em>--> <em><b>immigration_travel</b></em>, but the topic also contains <em>'apply', 'base', 'employee', 'job'</em> --> <em><b>employment_opportunities</b></em></li>\n",
    "</ul>\n",
    "<p> Of the five topics extracted, only 1 has up to 5 coherent words that indicate a topic of interest i.e topic 0 for <em><b>urban_mobility</b></em>. Topics 1 and 4 have sub topics in them that are not related to each other.This model is likely not the best fit for our data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d25b189f-7146-46ec-876f-4d8ac1d7cb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[report, area, car, close, fast, speed, metro, traffic, park, turn]</td>\n",
       "      <td>urban_mobility.traffic_regulations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[bank, rent, sell, send, week, property, cheap, order, option, charge]</td>\n",
       "      <td>accommodation/shopping_purchases/financial_services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mall, walk, reddit, video, stuff, outside, night, tip, visit, social]</td>\n",
       "      <td>recreation/social_media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[kid, care, hard, speak, sorry, culture, learn, situation, school, believe]</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[passport, allow, government, apply, travel, base, rule, employee, india, job]</td>\n",
       "      <td>employment_opportunities/immigration_travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                words  \\\n",
       "topic                                                                                   \n",
       "0                 [report, area, car, close, fast, speed, metro, traffic, park, turn]   \n",
       "1              [bank, rent, sell, send, week, property, cheap, order, option, charge]   \n",
       "2              [mall, walk, reddit, video, stuff, outside, night, tip, visit, social]   \n",
       "3         [kid, care, hard, speak, sorry, culture, learn, situation, school, believe]   \n",
       "4      [passport, allow, government, apply, travel, base, rule, employee, india, job]   \n",
       "\n",
       "                                                     label  \n",
       "topic                                                       \n",
       "0                       urban_mobility.traffic_regulations  \n",
       "1      accommodation/shopping_purchases/financial_services  \n",
       "2                                  recreation/social_media  \n",
       "3                                                education  \n",
       "4              employment_opportunities/immigration_travel  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#attach topic label to topic terms\n",
    "\n",
    "topic_label ={\n",
    "    0: \"urban_mobility.traffic_regulations\",\n",
    "    1: \"accommodation/shopping_purchases/financial_services\",\n",
    "    2: \"recreation/social_media\",\n",
    "    3: \"education\",\n",
    "    4: \"employment_opportunities/immigration_travel\",\n",
    "}\n",
    "\n",
    "model_1_topics_df['label'] = model_1_topics_df.index.map(topic_label)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(model_1_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7f5bd-5912-4c33-a892-fec72516a51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e702f061-7699-4567-93af-a4fd0425f116",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include column for most probable topic for each entry\n",
    "\n",
    "model_1_data = data.copy() #copy of the trainin data\n",
    "top_topic_per_document = [] #list to hold the topic with the highest probability for each row of texts in the data\n",
    "top_topic2_per_document = [] #list to hold the topic with the second highest probability for each row of texts in the data\n",
    "# Create a mapping from topics to labels\n",
    "topic_to_label = model_1_topics_df.set_index('topic')['label'].to_dict()\n",
    "\n",
    "\n",
    "for doc in bow:\n",
    "    topics = model_1.get_document_topics(doc, minimum_probability = 0)\n",
    "    top_topic = sorted(topics, key=lambda x: x[1], reverse = True)[0][0]\n",
    "    top_topic2 = sorted(topics, key=lambda x: x[1], reverse = True)[1][0]\n",
    "    top_topic_per_document.append(top_topic)\n",
    "    top_topic2_per_document.append(top_topic2)\n",
    "    \n",
    "#add column to data dataframe for the selected topic\n",
    "model_1_data['top_topic'] = top_topic_per_document\n",
    "# Map the top_topic to label\n",
    "model_1_data['label'] = model_1_data['top_topic'].map(topic_to_label)\n",
    "\n",
    "#add column to data dataframe for the selected topic\n",
    "model_1_data['topic_2'] = top_topic2_per_document\n",
    "# Map the top_topic to label\n",
    "model_1_data['label_2'] = model_1_data['topic_2'].map(topic_to_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951f949-6fc6-442f-a1bb-ff05db44a727",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#visually evaluate a small subset of submissions\n",
    "sample = model_1_data[model_1_data.text_type == 'submission'].sample(n = 10, random_state = 42)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(sample[['date_created', 'long_text', \"top_topic\",'label', \"topic_2\", 'label_2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c1cfd2-318d-45d0-93e9-16c985e6b7db",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434720ea-fa67-4925-b9a1-98e8c2132df7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>a. model 2: 10 topics</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d91ac16b-8421-4acd-9478-02f87f00df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = LdaModel.load('../models/model_2_10tpcs/lda_model_2_10tpcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "764d10ce-26c0-427e-a993-14d01b23dd3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10 topics:\n",
      "Coherence(c_v) = 0.4895138013398749,\n",
      "Coherence(c_npmi) = -0.02281372631638639,\n",
      "Coherence(u_mass) = -4.798116025994018,\n",
      "Perplexity = -8.206242643921952,\n",
      "Topic Diversity = 1.0\n",
      "\n",
      "Average similarity for topic 0: 0.7092\n",
      "Average similarity for topic 1: 0.5578\n",
      "Average similarity for topic 2: 0.4880\n",
      "Average similarity for topic 3: 0.5324\n",
      "Average similarity for topic 4: 0.5290\n",
      "Average similarity for topic 5: 0.6461\n",
      "Average similarity for topic 6: 0.5922\n",
      "Average similarity for topic 7: 0.3237\n",
      "Average similarity for topic 8: 0.4213\n",
      "Average similarity for topic 9: 0.4569\n"
     ]
    }
   ],
   "source": [
    "#quantitative evaluation\n",
    "eval_metrics (lda_model = model_2,docs = docs,\n",
    "              dictionary = dictionary, num_topics = model_2.num_topics, \n",
    "               corpus = bow, top_n = 10)\n",
    "\n",
    "average_similarity(lda_model = model_2, num_topics = model_2.num_topics, \n",
    "                   w2v_model = w2v_model, top_n=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9024b5ec-2e89-4f00-8479-f2cd7f0e4dd6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.023*\"fast\" + 0.021*\"car\" + 0.021*\"speed\" + 0.020*\"traffic\" + 0.017*\"limit\" + 0.015*\"license\" + 0.012*\"vehicle\" + 0.011*\"slow\" + 0.011*\"ticket\" + 0.011*\"plate\"'),\n",
       " (1,\n",
       "  '0.019*\"bank\" + 0.017*\"rent\" + 0.013*\"property\" + 0.011*\"send\" + 0.011*\"plan\" + 0.011*\"credit\" + 0.011*\"account\" + 0.010*\"sell\" + 0.010*\"market\" + 0.010*\"charge\"'),\n",
       " (2,\n",
       "  '0.010*\"area\" + 0.010*\"hour\" + 0.009*\"week\" + 0.009*\"close\" + 0.008*\"open\" + 0.008*\"walk\" + 0.008*\"visit\" + 0.007*\"mall\" + 0.007*\"away\" + 0.006*\"usually\"'),\n",
       " (3,\n",
       "  '0.030*\"speak\" + 0.029*\"learn\" + 0.028*\"school\" + 0.022*\"word\" + 0.019*\"arabic\" + 0.018*\"english\" + 0.017*\"play\" + 0.016*\"language\" + 0.015*\"rich\" + 0.013*\"fuck\"'),\n",
       " (4,\n",
       "  '0.025*\"test\" + 0.020*\"tip\" + 0.017*\"covid\" + 0.015*\"daily\" + 0.014*\"health\" + 0.012*\"thread\" + 0.010*\"positive\" + 0.009*\"medical\" + 0.009*\"pregnant\" + 0.009*\"june\"'),\n",
       " (5,\n",
       "  '0.018*\"report\" + 0.014*\"reddit\" + 0.012*\"message\" + 0.012*\"website\" + 0.011*\"video\" + 0.010*\"detail\" + 0.010*\"google\" + 0.010*\"write\" + 0.010*\"link\" + 0.008*\"news\"'),\n",
       " (6,\n",
       "  '0.026*\"cheap\" + 0.025*\"order\" + 0.024*\"restaurant\" + 0.023*\"delivery\" + 0.019*\"expensive\" + 0.015*\"quality\" + 0.014*\"contract\" + 0.014*\"bill\" + 0.013*\"store\" + 0.012*\"extra\"'),\n",
       " (7,\n",
       "  '0.021*\"middle\" + 0.015*\"agent\" + 0.015*\"class\" + 0.009*\"crime\" + 0.009*\"east\" + 0.009*\"low\" + 0.009*\"saudi\" + 0.009*\"project\" + 0.008*\"mask\" + 0.008*\"power\"'),\n",
       " (8,\n",
       "  '0.036*\"kid\" + 0.022*\"movie\" + 0.021*\"parent\" + 0.021*\"child\" + 0.021*\"wife\" + 0.019*\"muslim\" + 0.016*\"wear\" + 0.016*\"hate\" + 0.012*\"religion\" + 0.011*\"accident\"'),\n",
       " (9,\n",
       "  '0.007*\"care\" + 0.006*\"consider\" + 0.006*\"situation\" + 0.006*\"passport\" + 0.006*\"culture\" + 0.006*\"hard\" + 0.005*\"mention\" + 0.005*\"matter\" + 0.005*\"arab\" + 0.005*\"believe\"')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_2.print_topics(num_topics = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf521996-5ac5-42ca-93e0-b8b4eed73e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[fast, car, speed, traffic, limit, license, vehicle, slow, ticket, plate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[bank, rent, property, send, plan, credit, account, sell, market, charge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[area, hour, week, close, open, walk, visit, mall, away, usually]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[speak, learn, school, word, arabic, english, play, language, rich, fuck]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[test, tip, covid, daily, health, thread, positive, medical, pregnant, june]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[report, reddit, message, website, video, detail, google, write, link, news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[cheap, order, restaurant, delivery, expensive, quality, contract, bill, store, extra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[middle, agent, class, crime, east, low, saudi, project, mask, power]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[kid, movie, parent, child, wife, muslim, wear, hate, religion, accident]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[care, consider, situation, passport, culture, hard, mention, matter, arab, believe]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        words\n",
       "topic                                                                                        \n",
       "0                   [fast, car, speed, traffic, limit, license, vehicle, slow, ticket, plate]\n",
       "1                   [bank, rent, property, send, plan, credit, account, sell, market, charge]\n",
       "2                           [area, hour, week, close, open, walk, visit, mall, away, usually]\n",
       "3                   [speak, learn, school, word, arabic, english, play, language, rich, fuck]\n",
       "4                [test, tip, covid, daily, health, thread, positive, medical, pregnant, june]\n",
       "5                [report, reddit, message, website, video, detail, google, write, link, news]\n",
       "6      [cheap, order, restaurant, delivery, expensive, quality, contract, bill, store, extra]\n",
       "7                       [middle, agent, class, crime, east, low, saudi, project, mask, power]\n",
       "8                   [kid, movie, parent, child, wife, muslim, wear, hate, religion, accident]\n",
       "9        [care, consider, situation, passport, culture, hard, mention, matter, arab, believe]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset of topcis and topic representation\n",
    "num_topics = model_2.num_topics\n",
    "\n",
    "topics_words = []\n",
    "\n",
    "for topic in range(num_topics):\n",
    "    topic_words = model_2.show_topic(topic, topn = 10)\n",
    "    words = [word[0] for word in topic_words]\n",
    "    topics_words.append({\"topic\": topic, \"words\": words})\n",
    "    \n",
    "\n",
    "#create a dataframe\n",
    "model_2_topics_df = pd.DataFrame(topics_words)\n",
    "model_2_topics_df.set_index('topic', inplace =True)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(model_2_topics_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6735d5-4531-438a-9449-0cffab4c483b",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>topic 0: The top 10 words are all representative terms --> <em><b>urban_mobility.traffic_regulations</b></em>.</li><br>\n",
    "    <li>topic 1: <em> property', 'rent', 'sell'</em> -->  <em><b>real_estate_housing</b></em>. However, the terms <em> 'sell', 'market', 'charge',</em> --> <em><b>shopping and purchases</b></em>.Also, <em>'bank', 'credit', 'account', 'charge','send'</em> --> <em><b> banking/financial_services</b></em>.This topic contains three themes.</li><br>\n",
    "    <li>topic 2: <em>'mall', 'walk', 'visit'</em>might be said to indicate <em><b>recreation</b></em>, but its a bit of a stretch</li><br>\n",
    "    <li>topic 3: <em> 'speak', 'learn', 'school', 'word', 'language'</em> -->  <em><b>educational_services</b></em>. However, the terms <em> 'arabic', 'english', 'language'</em> --> <em><b>inter-cultural_relationships</b></em>.</li><br>\n",
    "    <li>topic 4: <em>'test', 'covid', 'health', 'positive', 'medical', 'pregnant'</em>--><em><b>health_services</b></em></li><br>\n",
    "    <li>topic 5: label --><em><b>communications_social_media</b></em></li><br>\n",
    "    <li> topic 6: terms belonging to two themes, labels --> <em><b>shopping/dining_experience</b></em>.</li><br>\n",
    "    <li>topic 7: contains a jumble of words that don't fit together to specify one coherent topic,  or a topic of interest</li><br>\n",
    "    <li>topic 8: <em>'kid', 'parent','child', 'wife'</em>--> <em><b>social_relationships</b></em>, <em>'muslim','religion', 'wear'</em>--> <em><b>religion</b></em></li><br>\n",
    "    <li>topic 9: contains a jumble of words that don't fit together to specify one coherent topic, or a topic of interest</li><br>\n",
    "</ul>\n",
    "<p> Of the 10 topics extracted, three have more than 5 terms that belong to a coherent topic, while two contain sub-topics. This model presents better granular topis than model 1, but is still unable to fully split different concepts into separate topics as seen in topics 1,2,3.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "53d02a5d-6cfc-4338-a147-232321ae3f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[fast, car, speed, traffic, limit, license, vehicle, slow, ticket, plate]</td>\n",
       "      <td>urban_mobility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[bank, rent, property, send, plan, credit, account, sell, market, charge]</td>\n",
       "      <td>financial_services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[area, hour, week, close, open, walk, visit, mall, away, usually]</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[speak, learn, school, word, arabic, english, play, language, rich, fuck]</td>\n",
       "      <td>educational_services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[test, tip, covid, daily, health, thread, positive, medical, pregnant, june]</td>\n",
       "      <td>health_services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[report, reddit, message, website, video, detail, google, write, link, news]</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[cheap, order, restaurant, delivery, expensive, quality, contract, bill, store, extra]</td>\n",
       "      <td>food/dining_experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[middle, agent, class, crime, east, low, saudi, project, mask, power]</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[kid, movie, parent, child, wife, muslim, wear, hate, religion, accident]</td>\n",
       "      <td>social_relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[care, consider, situation, passport, culture, hard, mention, matter, arab, believe]</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  \\\n",
       "0      0   \n",
       "1      1   \n",
       "2      2   \n",
       "3      3   \n",
       "4      4   \n",
       "5      5   \n",
       "6      6   \n",
       "7      7   \n",
       "8      8   \n",
       "9      9   \n",
       "\n",
       "                                                                                    words  \\\n",
       "0               [fast, car, speed, traffic, limit, license, vehicle, slow, ticket, plate]   \n",
       "1               [bank, rent, property, send, plan, credit, account, sell, market, charge]   \n",
       "2                       [area, hour, week, close, open, walk, visit, mall, away, usually]   \n",
       "3               [speak, learn, school, word, arabic, english, play, language, rich, fuck]   \n",
       "4            [test, tip, covid, daily, health, thread, positive, medical, pregnant, june]   \n",
       "5            [report, reddit, message, website, video, detail, google, write, link, news]   \n",
       "6  [cheap, order, restaurant, delivery, expensive, quality, contract, bill, store, extra]   \n",
       "7                   [middle, agent, class, crime, east, low, saudi, project, mask, power]   \n",
       "8               [kid, movie, parent, child, wife, muslim, wear, hate, religion, accident]   \n",
       "9    [care, consider, situation, passport, culture, hard, mention, matter, arab, believe]   \n",
       "\n",
       "                    label  \n",
       "0          urban_mobility  \n",
       "1      financial_services  \n",
       "2               undefined  \n",
       "3    educational_services  \n",
       "4         health_services  \n",
       "5               undefined  \n",
       "6  food/dining_experience  \n",
       "7               undefined  \n",
       "8    social_relationships  \n",
       "9               undefined  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#attach topic label to topic terms\n",
    "\n",
    "topic_label ={\n",
    "    0: \"urban_mobility\",\n",
    "    1: \"financial_services\",\n",
    "    2: \"undefined\",\n",
    "    3: \"educational_services\",\n",
    "    4: \"health_services\",\n",
    "    5: \"undefined\",\n",
    "    6: \"food/dining_experience\",\n",
    "    7: \"undefined\",\n",
    "    8: \"social_relationships\",\n",
    "    9: \"undefined\"\n",
    "}\n",
    "\n",
    "model_2_topics_df['label'] = model_2_topics_df['topic'].map(topic_label)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(model_2_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94c4a0a6-7a42-4dc5-a42c-b49761f8eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include column for most probable topic for each entry\n",
    "\n",
    "model_2_data = data.copy() #copy of the trainin data\n",
    "top_topic_per_document = [] #list to hold the topic with the highest probability for each row of texts in the data\n",
    "top_topic2_per_document = [] #list to hold the topic with the second highest probability for each row of texts in the data\n",
    "# Create a mapping from topics to labels\n",
    "topic_to_label = model_2_topics_df.set_index('topic')['label'].to_dict()\n",
    "\n",
    "\n",
    "for doc in bow:\n",
    "    topics = model_2.get_document_topics(doc, minimum_probability = 0)\n",
    "    top_topic = sorted(topics, key=lambda x: x[1], reverse = True)[0][0]\n",
    "    top_topic2 = sorted(topics, key=lambda x: x[1], reverse = True)[1][0]\n",
    "    top_topic_per_document.append(top_topic)\n",
    "    top_topic2_per_document.append(top_topic2)\n",
    "    \n",
    "#add column to data dataframe for the selected topic\n",
    "model_2_data['top_topic'] = top_topic_per_document\n",
    "# Map the top_topic to label\n",
    "model_2_data['label'] = model_2_data['top_topic'].map(topic_to_label)\n",
    "\n",
    "#add column to data dataframe for the selected topic\n",
    "model_2_data['topic_2'] = top_topic2_per_document\n",
    "# Map the top_topic to label\n",
    "model_2_data['label_2'] = model_2_data['topic_2'].map(topic_to_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a3f095ee-4493-4cea-8dbe-4b2bdc2a323c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_created</th>\n",
       "      <th>long_text</th>\n",
       "      <th>top_topic</th>\n",
       "      <th>label</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38303</th>\n",
       "      <td>2022-07-17 08:23:29</td>\n",
       "      <td>Anybody else been forced to start a business after losing a job, and wake up every morning wishing you never had to open your eyes? Every day is a minor heart attack asking yourself, \"can I do this ethically?\" All you see is people conning each other, and all you hear is, \"this is how you have to play the game\" I've been conned by people who I thought were friends. And then been in business with another \"friend\" with questionable business practices. I'm not suicidal, but I do keep wishing this would all end.</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined</td>\n",
       "      <td>8</td>\n",
       "      <td>social_relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59518</th>\n",
       "      <td>2023-06-18 20:08:38</td>\n",
       "      <td>require some suggestions - banking / accounts / loans Hi All,\\n\\nNeed some suggestions or opinions and better personal experiences.\\n\\nI have been banking and have account and credit cards with a bank here for almost a decade. It's a conventional bank, but sooner or later I am going to go for a home loan - for which I would prefer an Islamic bank. Should I open some account with an Islamic bank to have some relationship over period of time OR it doesn't matter - when the need to loan arises I can go for looking around for loan and based on my AECB reports bank would provide rates - so effectively meaning that longer or shorter relationship wouldn't mean anything it just that transaction and the score at the point of time which would matter?</td>\n",
       "      <td>1</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>2020-02-10 10:02:39</td>\n",
       "      <td>Current Global Economic Situation</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "      <td>7</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60089</th>\n",
       "      <td>2023-06-19 20:13:26</td>\n",
       "      <td>I need to get a broken hard disk repaired. I’ve got a ton of data on it with no backup. Any idea if there are any reliable places in Dubai or Sharjah for data recovery ? Tried searching online and didn’t find anything convincing.</td>\n",
       "      <td>1</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61240</th>\n",
       "      <td>2023-06-21 17:53:14</td>\n",
       "      <td>What to do when the neighbour parks like this? Hello Dubai community!\\n\\nGuys it is getting out of hands, I never met this guy, but he keeps on parking like this recently. \\n\\nAny advice from professional residents how to deal with this?</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>2020-05-11 11:11:08</td>\n",
       "      <td>Any news on gyms reopening? Does anybody have an insider scoop on when they're reopening?\\n\\nNewspaper people if you are reading you can chime in. In the form of a news article in 2 days or something.</td>\n",
       "      <td>5</td>\n",
       "      <td>undefined</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36450</th>\n",
       "      <td>2022-06-06 21:33:34</td>\n",
       "      <td>Experience with Techem ACs I’m planning to move in a building which has Techem as their AC providers. Can someone share their experience with the bills? I am hearing they are quite high.</td>\n",
       "      <td>6</td>\n",
       "      <td>food/dining_experience</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>2020-06-16 13:35:29</td>\n",
       "      <td>Entry permit validity Hey fellas, just came to know that the entry permit validity for residents stuck abroad is 21 days. It’s there on their website and the call centre also confirmed it. But given that many airports are still not opened up to international travel and fewer flights operating, what happens if one is not able to make it into UAE before the 21 day limit? Any input is appreciated. Thanks.</td>\n",
       "      <td>1</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52698</th>\n",
       "      <td>2023-04-19 08:54:12</td>\n",
       "      <td>Where can I find reasonably-priced jewelry and gold in Dubai? Looking to get my mam a gift Where can I find reasonably-priced jewelry and gold in Dubai? Looking to get my mam a gift</td>\n",
       "      <td>0</td>\n",
       "      <td>urban_mobility</td>\n",
       "      <td>3</td>\n",
       "      <td>educational_services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42845</th>\n",
       "      <td>2022-09-22 17:29:32</td>\n",
       "      <td>Any CUD current or former students here? If so, any advice, stories or highlights for a soon to be student at the Uni? General Uni advice appreciated as well. \\nI’m hopefully gonna be attending the spring semester next year and studying Computer Engineering but been getting cold feet since i don’t really know anyone there and don’t know what to expect.\\n\\n\\nAnd while i’ve heard plenty of praise for this Uni i’ve also heard rumors of there being a whole social status hierarchy deal going on which has me nervous-ish.\\n\\nEdit: Just so yk i already heard the song and dance of Unis here not being great but i don’t have a choice but to study in Dubai/Sharjah.</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56812</th>\n",
       "      <td>2023-05-28 12:32:53</td>\n",
       "      <td>Where to find scooter repair My scooter has been showing an error code (E7) and I'm not sure what could have caused it, there is no physical issue from what I can tell but whenever I try to drive it shows the error and shuts off and I won't be able to turn it on for a while. Anyone know how or where I can fix this? Thanks</td>\n",
       "      <td>4</td>\n",
       "      <td>health_services</td>\n",
       "      <td>0</td>\n",
       "      <td>urban_mobility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58071</th>\n",
       "      <td>2023-06-13 16:25:23</td>\n",
       "      <td>Home internet Which home internet connection is better\\nEtisilat or Du\\nI live in al nahda 2</td>\n",
       "      <td>5</td>\n",
       "      <td>undefined</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17577</th>\n",
       "      <td>2021-01-19 19:14:38</td>\n",
       "      <td>COVID restrictions on Indian passports are now lifted in UAE On Monday, the Indian Embassy announced that all previous restrictions on the reissue of passports, based on their expiry dates, would be reverted to pre-Covid proceedings.\\n\\n\"Any applicant may apply for re-issue of the passport at any of the nearest BLS centers in Abu Dhabi before one year of the expiry of the existing passport, as was done during the pre-Covid-19 periods,\" the mission stated in its latest advisory.\\n\\nHowever, the physical presence exemption for senior citizens (over 60 years of age), minor children (under 12 years of age), pregnant women and otherwise qualified applicants and the acceptance of passport applicants by the Public Relations Office of the Company (PRO) will continue until further notice.\\n\\nhttps://www.khaleejtimes.com/news/uae-covid-restrictions-on-indian-passport-services-lifted</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "      <td>1</td>\n",
       "      <td>financial_services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28651</th>\n",
       "      <td>2021-11-13 15:16:12</td>\n",
       "      <td>Any advice or help will be appreciated! Hello r\\Dubai \\n\\nI need a little help. \\n\\nI’m a 25 year old male, I have a Bachelor’s degree in Finance, the catch is, its from Africa because that’s where I’m originally from (also I’m white because apparently that matters in Dubai, not caucasian white but Arab white). \\n\\nI have opened a few businesses, two of which have hit the 6 figure mark and one hit 7. They’ve been successful and I’ve done rather well for myself ever since I started working, I’m a very fast learner, communicate very well, have good computer skills and can visualize an idea greatly. I am also fluent in Arabic, English and Hindi and can navigate my way through most situations in Italian but nowhere close to fluent. \\n\\nI have no experience in corporate work since I’ve always been self employed and managed people rather than be managed but my business ventures have been in an Arab country and I have experience with international trade a little bit. \\n\\nI’ve lost almost all assets due to a civil war in my country (force majeur) and am moving to Dubai to start over. \\n\\nI was wondering if there’s a chance consulting could be right for me and if anyone’s worked in the field before, and can share any tips it would be great.</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "      <td>3</td>\n",
       "      <td>educational_services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12613</th>\n",
       "      <td>2020-09-13 08:51:36</td>\n",
       "      <td>Who is getting a solid metal Tiger delivered to the marina by helicopter ?</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35805</th>\n",
       "      <td>2022-05-30 15:53:33</td>\n",
       "      <td>Can we just take a moment and appreciate how ridiculously great the infrastructure of Dubai is?</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42173</th>\n",
       "      <td>2022-09-10 00:02:57</td>\n",
       "      <td>How to get 1 year Multiple Entry Saudi E-Visa for GCC Residents (step-by-step guide)</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54682</th>\n",
       "      <td>2023-05-05 20:57:46</td>\n",
       "      <td>How binding is an employment contract? Hello everyone and happy Friday.\\n\\nI have a question, asking for a friend.\\n\\nLet say they accepted an job offer letter (and signed it) and even the contract was already signed by both parties (employer and my friend). Now, my friend changes their mind and decides to not go ahead with that company.\\n\\nJust to clarify, the Visa is not under process yet because the previous employer has not cancelled it yet.\\n\\nAlso, the contract with the new company states the following:\\n\\n“This Agreement shall enter in force and be valid for an unlimited period of time as of the day the Employee has effectively started her/his Duties with the Employer”.\\n\\nDoes this mean that the contract is not binding until the employee starts working with the company, and can be cancelled without repercussions?\\n\\nIs there any website or place where this can be checked?\\n\\nThank you and sorry for the long post!</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "      <td>1</td>\n",
       "      <td>financial_services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>2020-05-09 23:58:03</td>\n",
       "      <td>UAE announces rise in COVID-19 recoveries to 4,295, over 33,153 additional tests conducted, 624 new cases identified</td>\n",
       "      <td>4</td>\n",
       "      <td>health_services</td>\n",
       "      <td>1</td>\n",
       "      <td>financial_services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49835</th>\n",
       "      <td>2023-02-12 15:58:54</td>\n",
       "      <td>Liv Account So i used to have a Liv account back in my university days as it was the easiest to open and convenient to use card at the time however as the student visa changed it ended up to being a 3k minimum balance account i stopped using the card for after university the last time i had checked the app (probably 2021 or early 2022) the balance was in negatives since the penalty of 20-25 kept charging overtime for no maintenance, will this somehow affect my credit score in the future?\\n(I have tried to reopen the account to pay the amount off however Liv has almost shut down)</td>\n",
       "      <td>1</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>9</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date_created  \\\n",
       "38303  2022-07-17 08:23:29   \n",
       "59518  2023-06-18 20:08:38   \n",
       "3608   2020-02-10 10:02:39   \n",
       "60089  2023-06-19 20:13:26   \n",
       "61240  2023-06-21 17:53:14   \n",
       "6118   2020-05-11 11:11:08   \n",
       "36450  2022-06-06 21:33:34   \n",
       "9116   2020-06-16 13:35:29   \n",
       "52698  2023-04-19 08:54:12   \n",
       "42845  2022-09-22 17:29:32   \n",
       "56812  2023-05-28 12:32:53   \n",
       "58071  2023-06-13 16:25:23   \n",
       "17577  2021-01-19 19:14:38   \n",
       "28651  2021-11-13 15:16:12   \n",
       "12613  2020-09-13 08:51:36   \n",
       "35805  2022-05-30 15:53:33   \n",
       "42173  2022-09-10 00:02:57   \n",
       "54682  2023-05-05 20:57:46   \n",
       "5979   2020-05-09 23:58:03   \n",
       "49835  2023-02-12 15:58:54   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 long_text  \\\n",
       "38303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Anybody else been forced to start a business after losing a job, and wake up every morning wishing you never had to open your eyes? Every day is a minor heart attack asking yourself, \"can I do this ethically?\" All you see is people conning each other, and all you hear is, \"this is how you have to play the game\" I've been conned by people who I thought were friends. And then been in business with another \"friend\" with questionable business practices. I'm not suicidal, but I do keep wishing this would all end.   \n",
       "59518                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       require some suggestions - banking / accounts / loans Hi All,\\n\\nNeed some suggestions or opinions and better personal experiences.\\n\\nI have been banking and have account and credit cards with a bank here for almost a decade. It's a conventional bank, but sooner or later I am going to go for a home loan - for which I would prefer an Islamic bank. Should I open some account with an Islamic bank to have some relationship over period of time OR it doesn't matter - when the need to loan arises I can go for looking around for loan and based on my AECB reports bank would provide rates - so effectively meaning that longer or shorter relationship wouldn't mean anything it just that transaction and the score at the point of time which would matter?   \n",
       "3608                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Current Global Economic Situation    \n",
       "60089                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                I need to get a broken hard disk repaired. I’ve got a ton of data on it with no backup. Any idea if there are any reliable places in Dubai or Sharjah for data recovery ? Tried searching online and didn’t find anything convincing.   \n",
       "61240                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        What to do when the neighbour parks like this? Hello Dubai community!\\n\\nGuys it is getting out of hands, I never met this guy, but he keeps on parking like this recently. \\n\\nAny advice from professional residents how to deal with this?   \n",
       "6118                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Any news on gyms reopening? Does anybody have an insider scoop on when they're reopening?\\n\\nNewspaper people if you are reading you can chime in. In the form of a news article in 2 days or something.   \n",
       "36450                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Experience with Techem ACs I’m planning to move in a building which has Techem as their AC providers. Can someone share their experience with the bills? I am hearing they are quite high.   \n",
       "9116                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Entry permit validity Hey fellas, just came to know that the entry permit validity for residents stuck abroad is 21 days. It’s there on their website and the call centre also confirmed it. But given that many airports are still not opened up to international travel and fewer flights operating, what happens if one is not able to make it into UAE before the 21 day limit? Any input is appreciated. Thanks.   \n",
       "52698                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Where can I find reasonably-priced jewelry and gold in Dubai? Looking to get my mam a gift Where can I find reasonably-priced jewelry and gold in Dubai? Looking to get my mam a gift   \n",
       "42845                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Any CUD current or former students here? If so, any advice, stories or highlights for a soon to be student at the Uni? General Uni advice appreciated as well. \\nI’m hopefully gonna be attending the spring semester next year and studying Computer Engineering but been getting cold feet since i don’t really know anyone there and don’t know what to expect.\\n\\n\\nAnd while i’ve heard plenty of praise for this Uni i’ve also heard rumors of there being a whole social status hierarchy deal going on which has me nervous-ish.\\n\\nEdit: Just so yk i already heard the song and dance of Unis here not being great but i don’t have a choice but to study in Dubai/Sharjah.   \n",
       "56812                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Where to find scooter repair My scooter has been showing an error code (E7) and I'm not sure what could have caused it, there is no physical issue from what I can tell but whenever I try to drive it shows the error and shuts off and I won't be able to turn it on for a while. Anyone know how or where I can fix this? Thanks   \n",
       "58071                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Home internet Which home internet connection is better\\nEtisilat or Du\\nI live in al nahda 2   \n",
       "17577                                                                                                                                                                                                                                                                                                                                                                                COVID restrictions on Indian passports are now lifted in UAE On Monday, the Indian Embassy announced that all previous restrictions on the reissue of passports, based on their expiry dates, would be reverted to pre-Covid proceedings.\\n\\n\"Any applicant may apply for re-issue of the passport at any of the nearest BLS centers in Abu Dhabi before one year of the expiry of the existing passport, as was done during the pre-Covid-19 periods,\" the mission stated in its latest advisory.\\n\\nHowever, the physical presence exemption for senior citizens (over 60 years of age), minor children (under 12 years of age), pregnant women and otherwise qualified applicants and the acceptance of passport applicants by the Public Relations Office of the Company (PRO) will continue until further notice.\\n\\nhttps://www.khaleejtimes.com/news/uae-covid-restrictions-on-indian-passport-services-lifted   \n",
       "28651  Any advice or help will be appreciated! Hello r\\Dubai \\n\\nI need a little help. \\n\\nI’m a 25 year old male, I have a Bachelor’s degree in Finance, the catch is, its from Africa because that’s where I’m originally from (also I’m white because apparently that matters in Dubai, not caucasian white but Arab white). \\n\\nI have opened a few businesses, two of which have hit the 6 figure mark and one hit 7. They’ve been successful and I’ve done rather well for myself ever since I started working, I’m a very fast learner, communicate very well, have good computer skills and can visualize an idea greatly. I am also fluent in Arabic, English and Hindi and can navigate my way through most situations in Italian but nowhere close to fluent. \\n\\nI have no experience in corporate work since I’ve always been self employed and managed people rather than be managed but my business ventures have been in an Arab country and I have experience with international trade a little bit. \\n\\nI’ve lost almost all assets due to a civil war in my country (force majeur) and am moving to Dubai to start over. \\n\\nI was wondering if there’s a chance consulting could be right for me and if anyone’s worked in the field before, and can share any tips it would be great.   \n",
       "12613                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Who is getting a solid metal Tiger delivered to the marina by helicopter ?    \n",
       "35805                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Can we just take a moment and appreciate how ridiculously great the infrastructure of Dubai is?    \n",
       "42173                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                How to get 1 year Multiple Entry Saudi E-Visa for GCC Residents (step-by-step guide)    \n",
       "54682                                                                                                                                                                                                                                                                                                                               How binding is an employment contract? Hello everyone and happy Friday.\\n\\nI have a question, asking for a friend.\\n\\nLet say they accepted an job offer letter (and signed it) and even the contract was already signed by both parties (employer and my friend). Now, my friend changes their mind and decides to not go ahead with that company.\\n\\nJust to clarify, the Visa is not under process yet because the previous employer has not cancelled it yet.\\n\\nAlso, the contract with the new company states the following:\\n\\n“This Agreement shall enter in force and be valid for an unlimited period of time as of the day the Employee has effectively started her/his Duties with the Employer”.\\n\\nDoes this mean that the contract is not binding until the employee starts working with the company, and can be cancelled without repercussions?\\n\\nIs there any website or place where this can be checked?\\n\\nThank you and sorry for the long post!   \n",
       "5979                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 UAE announces rise in COVID-19 recoveries to 4,295, over 33,153 additional tests conducted, 624 new cases identified    \n",
       "49835                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Liv Account So i used to have a Liv account back in my university days as it was the easiest to open and convenient to use card at the time however as the student visa changed it ended up to being a 3k minimum balance account i stopped using the card for after university the last time i had checked the app (probably 2021 or early 2022) the balance was in negatives since the penalty of 20-25 kept charging overtime for no maintenance, will this somehow affect my credit score in the future?\\n(I have tried to reopen the account to pay the amount off however Liv has almost shut down)   \n",
       "\n",
       "       top_topic                   label  topic_2               label_2  \n",
       "38303          2               undefined        8  social_relationships  \n",
       "59518          1      financial_services        9             undefined  \n",
       "3608           9               undefined        7             undefined  \n",
       "60089          1      financial_services        2             undefined  \n",
       "61240          9               undefined        2             undefined  \n",
       "6118           5               undefined        9             undefined  \n",
       "36450          6  food/dining_experience        2             undefined  \n",
       "9116           1      financial_services        9             undefined  \n",
       "52698          0          urban_mobility        3  educational_services  \n",
       "42845          9               undefined        2             undefined  \n",
       "56812          4         health_services        0        urban_mobility  \n",
       "58071          5               undefined        2             undefined  \n",
       "17577          9               undefined        1    financial_services  \n",
       "28651          9               undefined        3  educational_services  \n",
       "12613          9               undefined        2             undefined  \n",
       "35805          9               undefined        2             undefined  \n",
       "42173          9               undefined        2             undefined  \n",
       "54682          9               undefined        1    financial_services  \n",
       "5979           4         health_services        1    financial_services  \n",
       "49835          1      financial_services        9             undefined  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visually evaluate a small subset of submissions\n",
    "sample = model_2_data[model_2_data.text_type == 'submission'].sample(n = 20, random_state = 42)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(sample[['date_created', 'long_text', \"top_topic\",'label', \"topic_2\", 'label_2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88165912-3a06-48ee-b398-12b36a959af9",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>c. model 2: 15 topics</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "987acd99-a9e5-46b4-b91f-c8a6c8a8ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = LdaModel.load('../models/model_3_15tpcs/lda_model_3_15tpcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee45d52c-6671-4f77-9782-0da7d72ac7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 15 topics:\n",
      "Coherence(c_v) = 0.46347251677274065,\n",
      "Coherence(c_npmi) = -0.026488737095068004,\n",
      "Coherence(u_mass) = -5.084119863191523,\n",
      "Perplexity = -8.920892722416768,\n",
      "Topic Diversity = 0.9933333333333333\n",
      "\n",
      "Average similarity for topic 0: 0.3907\n",
      "Average similarity for topic 1: 0.5440\n",
      "Average similarity for topic 2: 0.7234\n",
      "Average similarity for topic 3: 0.1976\n",
      "Average similarity for topic 4: 0.3399\n",
      "Average similarity for topic 5: 0.6650\n",
      "Average similarity for topic 6: 0.4382\n",
      "Average similarity for topic 7: 0.6379\n",
      "Average similarity for topic 8: 0.5084\n",
      "Average similarity for topic 9: 0.4833\n",
      "Average similarity for topic 10: 0.4693\n",
      "Average similarity for topic 11: 0.2890\n",
      "Average similarity for topic 12: 0.4452\n",
      "Average similarity for topic 13: 0.4227\n",
      "Average similarity for topic 14: 0.5073\n"
     ]
    }
   ],
   "source": [
    "#quantitative evaluation\n",
    "eval_metrics (lda_model = model_3,docs = docs,\n",
    "              dictionary = dictionary, num_topics = model_3.num_topics, \n",
    "               corpus = bow, top_n = 10)\n",
    "\n",
    "average_similarity(lda_model = model_3, num_topics = model_3.num_topics, \n",
    "                   w2v_model = w2v_model, top_n=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1dd8852c-f434-4316-acf4-0c4382def93c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.028*\"area\" + 0.027*\"mall\" + 0.027*\"walk\" + 0.020*\"wear\" + 0.020*\"visit\" + 0.020*\"dhabi\" + 0.017*\"public\" + 0.016*\"social\" + 0.015*\"rule\" + 0.015*\"hotel\"'),\n",
       " (1,\n",
       "  '0.020*\"rent\" + 0.017*\"sell\" + 0.015*\"property\" + 0.015*\"cheap\" + 0.015*\"order\" + 0.015*\"option\" + 0.014*\"restaurant\" + 0.013*\"charge\" + 0.013*\"delivery\" + 0.013*\"credit\"'),\n",
       " (2,\n",
       "  '0.027*\"fast\" + 0.025*\"second\" + 0.025*\"speed\" + 0.023*\"traffic\" + 0.022*\"line\" + 0.020*\"limit\" + 0.018*\"light\" + 0.016*\"pass\" + 0.013*\"slow\" + 0.012*\"park\"'),\n",
       " (3,\n",
       "  '0.047*\"report\" + 0.027*\"reddit\" + 0.026*\"stand\" + 0.023*\"middle\" + 0.022*\"door\" + 0.020*\"tip\" + 0.015*\"rental\" + 0.013*\"east\" + 0.010*\"brother\" + 0.010*\"dear\"'),\n",
       " (4,\n",
       "  '0.021*\"sense\" + 0.021*\"soon\" + 0.016*\"common\" + 0.013*\"possible\" + 0.011*\"amazing\" + 0.010*\"expect\" + 0.009*\"demand\" + 0.008*\"app\" + 0.008*\"culture\" + 0.007*\"past\"'),\n",
       " (5,\n",
       "  '0.018*\"bank\" + 0.017*\"send\" + 0.015*\"phone\" + 0.013*\"account\" + 0.013*\"online\" + 0.012*\"website\" + 0.011*\"contact\" + 0.011*\"email\" + 0.010*\"process\" + 0.009*\"book\"'),\n",
       " (6,\n",
       "  '0.033*\"hour\" + 0.032*\"kid\" + 0.030*\"week\" + 0.025*\"school\" + 0.025*\"hand\" + 0.021*\"seat\" + 0.017*\"parent\" + 0.013*\"clean\" + 0.012*\"early\" + 0.012*\"travel\"'),\n",
       " (7,\n",
       "  '0.014*\"arab\" + 0.014*\"government\" + 0.012*\"indian\" + 0.012*\"culture\" + 0.012*\"india\" + 0.010*\"true\" + 0.010*\"expat\" + 0.010*\"western\" + 0.009*\"nationality\" + 0.008*\"racism\"'),\n",
       " (8,\n",
       "  '0.029*\"insurance\" + 0.028*\"test\" + 0.024*\"car\" + 0.021*\"license\" + 0.021*\"cover\" + 0.017*\"vehicle\" + 0.016*\"tenant\" + 0.016*\"expense\" + 0.013*\"plate\" + 0.012*\"fail\"'),\n",
       " (9,\n",
       "  '0.032*\"muslim\" + 0.020*\"religion\" + 0.020*\"room\" + 0.017*\"hate\" + 0.016*\"steal\" + 0.014*\"totally\" + 0.014*\"ban\" + 0.014*\"pregnant\" + 0.013*\"flag\" + 0.012*\"pray\"'),\n",
       " (10,\n",
       "  '0.033*\"build\" + 0.030*\"building\" + 0.023*\"parking\" + 0.016*\"private\" + 0.015*\"game\" + 0.015*\"play\" + 0.015*\"space\" + 0.014*\"inside\" + 0.014*\"villa\" + 0.012*\"spot\"'),\n",
       " (11,\n",
       "  '0.034*\"metro\" + 0.033*\"happy\" + 0.033*\"station\" + 0.027*\"sharjah\" + 0.021*\"daily\" + 0.018*\"thread\" + 0.018*\"video\" + 0.015*\"noon\" + 0.015*\"luck\" + 0.013*\"group\"'),\n",
       " (12,\n",
       "  '0.019*\"away\" + 0.014*\"situation\" + 0.013*\"lose\" + 0.013*\"story\" + 0.013*\"sorry\" + 0.013*\"girl\" + 0.011*\"security\" + 0.011*\"wife\" + 0.010*\"face\" + 0.010*\"debt\"'),\n",
       " (13,\n",
       "  '0.026*\"speak\" + 0.023*\"date\" + 0.022*\"watch\" + 0.020*\"movie\" + 0.018*\"arabic\" + 0.017*\"english\" + 0.015*\"language\" + 0.014*\"drink\" + 0.013*\"chicken\" + 0.012*\"cool\"'),\n",
       " (14,\n",
       "  '0.016*\"care\" + 0.013*\"passport\" + 0.012*\"believe\" + 0.011*\"accept\" + 0.010*\"employee\" + 0.009*\"hard\" + 0.009*\"child\" + 0.009*\"learn\" + 0.009*\"job\" + 0.008*\"consider\"')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_3.print_topics(num_topics = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "523a8178-0f67-4695-8027-979ea76e385a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[area, mall, walk, wear, visit, dhabi, public, social, rule, hotel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[rent, sell, property, cheap, order, option, restaurant, charge, delivery, credit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fast, second, speed, traffic, line, limit, light, pass, slow, park]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[report, reddit, stand, middle, door, tip, rental, east, brother, dear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[sense, soon, common, possible, amazing, expect, demand, app, culture, past]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[bank, send, phone, account, online, website, contact, email, process, book]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[hour, kid, week, school, hand, seat, parent, clean, early, travel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[arab, government, indian, culture, india, true, expat, western, nationality, racism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[insurance, test, car, license, cover, vehicle, tenant, expense, plate, fail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[muslim, religion, room, hate, steal, totally, ban, pregnant, flag, pray]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[build, building, parking, private, game, play, space, inside, villa, spot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[metro, happy, station, sharjah, daily, thread, video, noon, luck, group]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[away, situation, lose, story, sorry, girl, security, wife, face, debt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[speak, date, watch, movie, arabic, english, language, drink, chicken, cool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[care, passport, believe, accept, employee, hard, child, learn, job, consider]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       words\n",
       "topic                                                                                       \n",
       "0                        [area, mall, walk, wear, visit, dhabi, public, social, rule, hotel]\n",
       "1         [rent, sell, property, cheap, order, option, restaurant, charge, delivery, credit]\n",
       "2                       [fast, second, speed, traffic, line, limit, light, pass, slow, park]\n",
       "3                    [report, reddit, stand, middle, door, tip, rental, east, brother, dear]\n",
       "4               [sense, soon, common, possible, amazing, expect, demand, app, culture, past]\n",
       "5               [bank, send, phone, account, online, website, contact, email, process, book]\n",
       "6                        [hour, kid, week, school, hand, seat, parent, clean, early, travel]\n",
       "7      [arab, government, indian, culture, india, true, expat, western, nationality, racism]\n",
       "8              [insurance, test, car, license, cover, vehicle, tenant, expense, plate, fail]\n",
       "9                  [muslim, religion, room, hate, steal, totally, ban, pregnant, flag, pray]\n",
       "10               [build, building, parking, private, game, play, space, inside, villa, spot]\n",
       "11                 [metro, happy, station, sharjah, daily, thread, video, noon, luck, group]\n",
       "12                   [away, situation, lose, story, sorry, girl, security, wife, face, debt]\n",
       "13              [speak, date, watch, movie, arabic, english, language, drink, chicken, cool]\n",
       "14            [care, passport, believe, accept, employee, hard, child, learn, job, consider]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset of topcis and topic representation\n",
    "num_topics = model_3.num_topics\n",
    "\n",
    "topics_words = []\n",
    "\n",
    "for topic in range(num_topics):\n",
    "    topic_words = model_3.show_topic(topic, topn = 10)\n",
    "    words = [word[0] for word in topic_words]\n",
    "    topics_words.append({\"topic\": topic, \"words\": words})\n",
    "    \n",
    "\n",
    "#create a dataframe\n",
    "model_3_topics_df = pd.DataFrame(topics_words)\n",
    "model_3_topics_df.set_index('topic', inplace =True)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(model_3_topics_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcbb64c-1b53-4a81-b050-f455752dcd3c",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>topic 0: contains terms that belong to different themes,and cannot fit into one main coherent them</li><br>\n",
    "    <li>topic 1: <em>'rent', 'sell', 'property', 'cheap'</em>--><em><b>real_estate_housing</b></em>. But also, <em>cheap', 'order', 'restaurant', 'delivery'</em>--><em><b>food_dining_services</b></em>, but also, <em>'order', 'option', 'charge', 'credit'</em>--><em><b>shopping_services</b></em></li><br>\n",
    "    <li>topic 2: <em>'fast', 'speed', 'traffic', 'limit', 'light', 'pass', 'slow'</em>--><em><b>urban_mobility.traffic_regulations</b></em></li><br>\n",
    "    <li>topic 3: non_context</li><br>\n",
    "    <li>topic 4: non_context </li><br>\n",
    "    <li>topic 5: contains terms that belong to different themes,and cannot fit into one main coherent theme</li><br>\n",
    "    <li>topic 6: jumbo of terms that fit into different categories</li><br>\n",
    "    <li>topic 7: <em>'arab', 'indian', 'india', 'expat', 'western', 'nationality'</em>--><em><b>international_communities</b></em></li><br>\n",
    "    <li>topic 8:<em> 'insurance', 'test', 'car', 'license', 'cover', 'vehicle', 'plate'</em>--><em><b>urban_mobility.car_ownership</b></em></li><br>\n",
    "    <li>topic 9: <em> 'muslim', 'religion', 'pray'</em>--><em><b>religious practices</b></em> but also contains other terms that belong to other themes.</li><br>\n",
    "    <li>topic 10: contains terms that belong to different themes,and cannot fit into one main coherent theme</li><br>\n",
    "    <li>topic 11: contains terms that belong to different themes,and cannot fit into one main coherent theme</li><br>\n",
    "    <li>topic 12: contains terms that belong to different themes,and cannot fit into one main coherent theme</li><br>\n",
    "    <li>topic 13:<em>'date', 'watch', 'movie', 'drink'</em>--><em><b>social_activities</b></em>, but also includes other terms that do not fit</li><br>\n",
    "    <li>topic 14: contains terms that belong to different themes,and cannot fit into one main coherent theme</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "25187d85-1a26-471b-acc1-123bef17d3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[area, mall, walk, wear, visit, dhabi, public, social, rule, hotel]</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[rent, sell, property, cheap, order, option, restaurant, charge, delivery, credit]</td>\n",
       "      <td>real_estate_housing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[fast, second, speed, traffic, line, limit, light, pass, slow, park]</td>\n",
       "      <td>urban_mobility.traffic_regulations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[report, reddit, stand, middle, door, tip, rental, east, brother, dear]</td>\n",
       "      <td>non_context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[sense, soon, common, possible, amazing, expect, demand, app, culture, past]</td>\n",
       "      <td>non_context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[bank, send, phone, account, online, website, contact, email, process, book]</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[hour, kid, week, school, hand, seat, parent, clean, early, travel]</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[arab, government, indian, culture, india, true, expat, western, nationality, racism]</td>\n",
       "      <td>international_communities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[insurance, test, car, license, cover, vehicle, tenant, expense, plate, fail]</td>\n",
       "      <td>urban_mobility.car_ownership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[muslim, religion, room, hate, steal, totally, ban, pregnant, flag, pray]</td>\n",
       "      <td>religious_practices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>[build, building, parking, private, game, play, space, inside, villa, spot]</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>[metro, happy, station, sharjah, daily, thread, video, noon, luck, group]</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>[away, situation, lose, story, sorry, girl, security, wife, face, debt]</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>[speak, date, watch, movie, arabic, english, language, drink, chicken, cool]</td>\n",
       "      <td>social_activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[care, passport, believe, accept, employee, hard, child, learn, job, consider]</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       2   \n",
       "3       3   \n",
       "4       4   \n",
       "5       5   \n",
       "6       6   \n",
       "7       7   \n",
       "8       8   \n",
       "9       9   \n",
       "10     10   \n",
       "11     11   \n",
       "12     12   \n",
       "13     13   \n",
       "14     14   \n",
       "\n",
       "                                                                                    words  \\\n",
       "0                     [area, mall, walk, wear, visit, dhabi, public, social, rule, hotel]   \n",
       "1      [rent, sell, property, cheap, order, option, restaurant, charge, delivery, credit]   \n",
       "2                    [fast, second, speed, traffic, line, limit, light, pass, slow, park]   \n",
       "3                 [report, reddit, stand, middle, door, tip, rental, east, brother, dear]   \n",
       "4            [sense, soon, common, possible, amazing, expect, demand, app, culture, past]   \n",
       "5            [bank, send, phone, account, online, website, contact, email, process, book]   \n",
       "6                     [hour, kid, week, school, hand, seat, parent, clean, early, travel]   \n",
       "7   [arab, government, indian, culture, india, true, expat, western, nationality, racism]   \n",
       "8           [insurance, test, car, license, cover, vehicle, tenant, expense, plate, fail]   \n",
       "9               [muslim, religion, room, hate, steal, totally, ban, pregnant, flag, pray]   \n",
       "10            [build, building, parking, private, game, play, space, inside, villa, spot]   \n",
       "11              [metro, happy, station, sharjah, daily, thread, video, noon, luck, group]   \n",
       "12                [away, situation, lose, story, sorry, girl, security, wife, face, debt]   \n",
       "13           [speak, date, watch, movie, arabic, english, language, drink, chicken, cool]   \n",
       "14         [care, passport, believe, accept, employee, hard, child, learn, job, consider]   \n",
       "\n",
       "                                 label  \n",
       "0                            undefined  \n",
       "1                  real_estate_housing  \n",
       "2   urban_mobility.traffic_regulations  \n",
       "3                          non_context  \n",
       "4                          non_context  \n",
       "5                            undefined  \n",
       "6                            undefined  \n",
       "7            international_communities  \n",
       "8         urban_mobility.car_ownership  \n",
       "9                  religious_practices  \n",
       "10                           undefined  \n",
       "11                           undefined  \n",
       "12                           undefined  \n",
       "13                   social_activities  \n",
       "14                           undefined  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#attach topic label to topic terms\n",
    "\n",
    "topic_label ={\n",
    "    0: \"undefined\",\n",
    "    1: \"real_estate_housing\",\n",
    "    2: \"urban_mobility.traffic_regulations\",\n",
    "    3: \"non_context\",\n",
    "    4: \"non_context\",\n",
    "    5: \"undefined\",\n",
    "    6: \"undefined\",\n",
    "    7: \"international_communities\",\n",
    "    8: \"urban_mobility.car_ownership\",\n",
    "    9: \"religious_practices\",\n",
    "    10: \"undefined\",\n",
    "    11: \"undefined\",\n",
    "    12: \"undefined\",\n",
    "    13: \"social_activities\",\n",
    "    14: \"undefined\"\n",
    "}\n",
    "\n",
    "model_3_topics_df['label'] = model_3_topics_df['topic'].map(topic_label)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(model_3_topics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3bbad5-a714-4942-a7d7-796d66aa68c8",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>d. model 4: 20 topics</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f18e280b-984c-4194-b680-fe16fb891d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = LdaModel.load('../models/model_4_20tpcs/lda_model_4_20tpcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aba3e1b7-cf6b-4f3a-ad22-90c96555b35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 20 topics:\n",
      "Coherence(c_v) = 0.45719477033031203,\n",
      "Coherence(c_npmi) = -0.0282779422731149,\n",
      "Coherence(u_mass) = -4.898497802637102,\n",
      "Perplexity = -9.179299779882598,\n",
      "Topic Diversity = 1.0\n",
      "\n",
      "Average similarity for topic 0: 0.5438\n",
      "Average similarity for topic 1: 0.5287\n",
      "Average similarity for topic 2: 0.3807\n",
      "Average similarity for topic 3: 0.5684\n",
      "Average similarity for topic 4: 0.2829\n",
      "Average similarity for topic 5: 0.4078\n",
      "Average similarity for topic 6: 0.6791\n",
      "Average similarity for topic 7: 0.5954\n",
      "Average similarity for topic 8: 0.4531\n",
      "Average similarity for topic 9: 0.2947\n",
      "Average similarity for topic 10: 0.4836\n",
      "Average similarity for topic 11: 0.4723\n",
      "Average similarity for topic 12: 0.5367\n",
      "Average similarity for topic 13: 0.3404\n",
      "Average similarity for topic 14: 0.4035\n",
      "Average similarity for topic 15: 0.5397\n",
      "Average similarity for topic 16: 0.3451\n",
      "Average similarity for topic 17: 0.5108\n",
      "Average similarity for topic 18: 0.5223\n",
      "Average similarity for topic 19: 0.6429\n"
     ]
    }
   ],
   "source": [
    "#quantitative evaluation\n",
    "eval_metrics (lda_model = model_4,docs = docs,\n",
    "              dictionary = dictionary, num_topics = model_4.num_topics, \n",
    "               corpus = bow, top_n = 10)\n",
    "\n",
    "average_similarity(lda_model = model_4, num_topics = model_4.num_topics, \n",
    "                   w2v_model = w2v_model, top_n=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4f93c11e-80b6-4072-80b4-99552312a809",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[spend, compare, save, class, rate, earn, government, worker, increase, income]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[kid, hard, child, lose, accept, parent, care, exist, support, grow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[play, owner, game, project, damn, lmao, build, fuel, fair, valid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apply, travel, passport, emirate, employee, require, process, book, hour, cancel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[watch, arab, movie, station, scam, social, racist, clearly, medium, opinion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[safe, airport, center, coffee, space, address, train, burj, accommodation, jumeirah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[phone, send, reddit, message, video, link, website, answer, picture, block]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[speak, arabic, english, language, indian, word, learn, european, american, apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[sound, hand, wife, head, clean, taxi, crime, weird, paper, special]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[test, agent, sense, common, female, fuck, covid, gender, result, damage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[order, delivery, fast, speed, restaurant, customer, charge, limit, bill, pass]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[area, mall, apartment, week, house, walk, building, dhabi, landlord, security]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[report, sorry, situation, matter, believe, india, hate, authority, complain, seriously]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[date, away, stand, girl, line, door, visit, car, white, parking]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[property, soon, possible, estate, recommend, fake, invest, story, letter, oman]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[allow, culture, respect, muslim, community, law, human, remove, illegal, religion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[school, mistake, willing, teach, treat, amazon, noon, fire, demand, return]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[wear, rule, outside, enter, mask, risk, holiday, face, public, clothe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[bank, rent, option, plan, account, credit, advice, email, legal, insurance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[sell, cheap, stuff, seat, store, expensive, shop, buy, quality, brand]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          words\n",
       "topic                                                                                          \n",
       "0               [spend, compare, save, class, rate, earn, government, worker, increase, income]\n",
       "1                          [kid, hard, child, lose, accept, parent, care, exist, support, grow]\n",
       "2                            [play, owner, game, project, damn, lmao, build, fuel, fair, valid]\n",
       "3            [apply, travel, passport, emirate, employee, require, process, book, hour, cancel]\n",
       "4                 [watch, arab, movie, station, scam, social, racist, clearly, medium, opinion]\n",
       "5         [safe, airport, center, coffee, space, address, train, burj, accommodation, jumeirah]\n",
       "6                  [phone, send, reddit, message, video, link, website, answer, picture, block]\n",
       "7            [speak, arabic, english, language, indian, word, learn, european, american, apple]\n",
       "8                          [sound, hand, wife, head, clean, taxi, crime, weird, paper, special]\n",
       "9                     [test, agent, sense, common, female, fuck, covid, gender, result, damage]\n",
       "10              [order, delivery, fast, speed, restaurant, customer, charge, limit, bill, pass]\n",
       "11              [area, mall, apartment, week, house, walk, building, dhabi, landlord, security]\n",
       "12     [report, sorry, situation, matter, believe, india, hate, authority, complain, seriously]\n",
       "13                            [date, away, stand, girl, line, door, visit, car, white, parking]\n",
       "14             [property, soon, possible, estate, recommend, fake, invest, story, letter, oman]\n",
       "15          [allow, culture, respect, muslim, community, law, human, remove, illegal, religion]\n",
       "16                 [school, mistake, willing, teach, treat, amazon, noon, fire, demand, return]\n",
       "17                      [wear, rule, outside, enter, mask, risk, holiday, face, public, clothe]\n",
       "18                 [bank, rent, option, plan, account, credit, advice, email, legal, insurance]\n",
       "19                      [sell, cheap, stuff, seat, store, expensive, shop, buy, quality, brand]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset of topcis and topic representation\n",
    "num_topics = model_4.num_topics\n",
    "\n",
    "topics_words = []\n",
    "\n",
    "for topic in range(num_topics):\n",
    "    topic_words = model_4.show_topic(topic, topn = 10)\n",
    "    words = [word[0] for word in topic_words]\n",
    "    topics_words.append({\"topic\": topic, \"words\": words})\n",
    "    \n",
    "\n",
    "#create a dataframe\n",
    "model_4_topics_df = pd.DataFrame(topics_words)\n",
    "model_4_topics_df.set_index('topic', inplace =True)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(model_4_topics_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4abe97f-e15b-4ab9-95af-953c53c29fa8",
   "metadata": {},
   "source": [
    "This model seems to have more merged topics\n",
    "<ul>\n",
    "    <li>topic 0: Label --><em><b>income</b></em>. Terms all revolve around income, except maybe for <em>'class', 'compare'</em>.</li><br>\n",
    "    <li>topic 1: Label --> <em><b>social_relationships.childcare</b></em>. Terms mostly revolve around childcare, except maybe for <em>'hard', 'accept'</em>.</li><br>\n",
    "    <li>topic 2: <em>'play', 'game'</em> can be labelled --> <em><b>entertainment</b></em> but none of the other terms fit in.</li><br>\n",
    "    <li>topic 3: label--><em><b>immigration.travel_procedures</b></em>. All the terms fit except maybe for <em>employee.</em></li><br>\n",
    "    <li>topic 4: terms cannot clearly be fit into one or related themes, or a theme we are interested in. label --> <em><b>undefined.</b></em></li><br>\n",
    "    <li>topic 5: labels --> <em><b>infrastructure.landmarks/amenities</b></em>. Most terms fit except for 'accommodation' maybe.</li><br>\n",
    "    <li>topic 6: labels --> <em><b>communication_media</b></em></li><br>\n",
    "    <li>topic 7: labels --> <em><b>international_communities</b></em>. All terms seem to fit except 'apple'</li><br>\n",
    "    <li>topic 8: a jumble of terms that dont share a coherent theme<li><br>\n",
    "    <li>topic 9: a jumble of terms that dont share a coherent theme<li><br>\n",
    "    <li>topic 10: label --> <em><b>food_dining_services</b></em></li><br>\n",
    "    <li>topic 11: a mix of terms for <em><b>housing</b></em> and <em><b>infrastructure.amenities</b></em></li><br>\n",
    "    <li>topic 12: terms cannot clearly be fit into one or related themes, or a theme we are interested in. label --> <em><b>undefined.</b></em></li><br>\n",
    "    <li>topic 13: a jumble of terms that dont share a coherent theme<li><br>\n",
    "    <li>topic 14: a jumble of terms that dont share a coherent theme<li><br>\n",
    "    <li>topic 15: label --> <em><b>culture_norms</b></em></li><br>\n",
    "    <li>topic 16: a jumble of terms that dont share a coherent theme<li><br>\n",
    "    <li>topic 17: label --> <em><b>health.COVID</b></em>. These terms relate to behaviors exhibited during the COVID pandemic</li><br>\n",
    "    <li>topic 18: some terms like <em>'bank', 'plan', 'account', 'credit'</em> are related to label --><em><b>financial_services</b></em></li><br>\n",
    "    <li> topic 19: label --> <em><b>shopping_services</b></em></li><br>\n",
    "        \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45597729-61b1-4d75-a58b-e04c023f820a",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>d. model 5: 25 topics</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2410a8ea-295b-4574-8b4f-ba410bc3509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = LdaModel.load('../models/model_5_25tpcs/lda_model_5_25tpcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0eff1ec6-f4dc-4149-a7c2-f3943500c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 25 topics:\n",
      "Coherence(c_v) = 0.4370927325782465,\n",
      "Coherence(c_npmi) = -0.04470407911136721,\n",
      "Coherence(u_mass) = -5.184369933326291,\n",
      "Perplexity = -9.434405649658327,\n",
      "Topic Diversity = 1.0\n",
      "\n",
      "Average similarity for topic 0: 0.4606\n",
      "Average similarity for topic 1: 0.4066\n",
      "Average similarity for topic 2: 0.4484\n",
      "Average similarity for topic 3: 0.5007\n",
      "Average similarity for topic 4: 0.3327\n",
      "Average similarity for topic 5: 0.3551\n",
      "Average similarity for topic 6: 0.5517\n",
      "Average similarity for topic 7: 0.3855\n",
      "Average similarity for topic 8: 0.5423\n",
      "Average similarity for topic 9: 0.5204\n",
      "Average similarity for topic 10: 0.5186\n",
      "Average similarity for topic 11: 0.4796\n",
      "Average similarity for topic 12: 0.3581\n",
      "Average similarity for topic 13: 0.3215\n",
      "Average similarity for topic 14: 0.6221\n",
      "Average similarity for topic 15: 0.6366\n",
      "Average similarity for topic 16: 0.5926\n",
      "Average similarity for topic 17: 0.5678\n",
      "Average similarity for topic 18: 0.4921\n",
      "Average similarity for topic 19: 0.3593\n",
      "Average similarity for topic 20: 0.3360\n",
      "Average similarity for topic 21: 0.5545\n",
      "Average similarity for topic 22: 0.5772\n",
      "Average similarity for topic 23: 0.4741\n",
      "Average similarity for topic 24: 0.4152\n"
     ]
    }
   ],
   "source": [
    "#quantitative evaluation\n",
    "eval_metrics (lda_model = model_5,docs = docs,\n",
    "              dictionary = dictionary, num_topics = model_5.num_topics, \n",
    "               corpus = bow, top_n = 10)\n",
    "\n",
    "average_similarity(lda_model = model_5, num_topics = model_5.num_topics, \n",
    "                   w2v_model = w2v_model, top_n=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "79dcbfe9-2bae-4e61-9ead-b47fc76d686c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.038*\"report\" + 0.028*\"passport\" + 0.026*\"travel\" + 0.020*\"process\" + 0.019*\"emirate\" + 0.018*\"email\" + 0.018*\"contract\" + 0.017*\"wear\" + 0.017*\"cancel\" + 0.016*\"court\"'),\n",
       " (1,\n",
       "  '0.037*\"owner\" + 0.036*\"head\" + 0.035*\"turn\" + 0.030*\"hotel\" + 0.028*\"room\" + 0.021*\"light\" + 0.019*\"lmao\" + 0.017*\"bother\" + 0.017*\"curious\" + 0.015*\"fresh\"'),\n",
       " (2,\n",
       "  '0.029*\"hand\" + 0.023*\"face\" + 0.022*\"sense\" + 0.019*\"hold\" + 0.017*\"common\" + 0.016*\"literally\" + 0.015*\"public\" + 0.015*\"short\" + 0.012*\"stupid\" + 0.012*\"absolutely\"'),\n",
       " (3,\n",
       "  '0.038*\"away\" + 0.037*\"date\" + 0.033*\"walk\" + 0.025*\"stand\" + 0.024*\"park\" + 0.024*\"girl\" + 0.022*\"line\" + 0.021*\"security\" + 0.017*\"drop\" + 0.017*\"seat\"'),\n",
       " (4,\n",
       "  '0.051*\"arab\" + 0.035*\"landlord\" + 0.032*\"arabic\" + 0.025*\"difference\" + 0.023*\"raise\" + 0.023*\"chicken\" + 0.018*\"saudi\" + 0.018*\"shawarma\" + 0.015*\"fake\" + 0.015*\"bear\"'),\n",
       " (5,\n",
       "  '0.044*\"notice\" + 0.033*\"quality\" + 0.030*\"scam\" + 0.026*\"clean\" + 0.024*\"minimum\" + 0.023*\"poor\" + 0.022*\"complain\" + 0.022*\"wage\" + 0.020*\"super\" + 0.017*\"apple\"'),\n",
       " (6,\n",
       "  '0.038*\"care\" + 0.026*\"accept\" + 0.023*\"allow\" + 0.021*\"respect\" + 0.020*\"rule\" + 0.020*\"muslim\" + 0.018*\"treat\" + 0.015*\"follow\" + 0.013*\"force\" + 0.013*\"okay\"'),\n",
       " (7,\n",
       "  '0.050*\"speak\" + 0.041*\"house\" + 0.040*\"deal\" + 0.037*\"remember\" + 0.032*\"agent\" + 0.026*\"estate\" + 0.023*\"english\" + 0.020*\"lose\" + 0.018*\"afford\" + 0.017*\"villa\"'),\n",
       " (8,\n",
       "  '0.060*\"rent\" + 0.053*\"area\" + 0.037*\"apartment\" + 0.037*\"cheap\" + 0.033*\"expensive\" + 0.031*\"building\" + 0.027*\"depend\" + 0.018*\"canada\" + 0.018*\"plan\" + 0.016*\"trip\"'),\n",
       " (9,\n",
       "  '0.070*\"bank\" + 0.045*\"phone\" + 0.041*\"account\" + 0.038*\"charge\" + 0.031*\"soon\" + 0.025*\"bill\" + 0.023*\"possible\" + 0.021*\"parking\" + 0.021*\"sharjah\" + 0.019*\"transaction\"'),\n",
       " (10,\n",
       "  '0.036*\"station\" + 0.032*\"build\" + 0.019*\"interest\" + 0.019*\"metro\" + 0.019*\"fill\" + 0.019*\"recommend\" + 0.018*\"advance\" + 0.018*\"available\" + 0.017*\"special\" + 0.015*\"solution\"'),\n",
       " (11,\n",
       "  '0.045*\"kid\" + 0.036*\"school\" + 0.033*\"middle\" + 0.027*\"parent\" + 0.027*\"child\" + 0.026*\"class\" + 0.018*\"father\" + 0.018*\"meet\" + 0.017*\"wife\" + 0.016*\"summer\"'),\n",
       " (12,\n",
       "  '0.045*\"property\" + 0.038*\"test\" + 0.031*\"worker\" + 0.026*\"rich\" + 0.023*\"rate\" + 0.022*\"covid\" + 0.020*\"million\" + 0.018*\"result\" + 0.018*\"condition\" + 0.017*\"burger\"'),\n",
       " (13,\n",
       "  '0.043*\"dhabi\" + 0.042*\"true\" + 0.036*\"sound\" + 0.035*\"tip\" + 0.026*\"private\" + 0.025*\"miss\" + 0.023*\"near\" + 0.020*\"crazy\" + 0.015*\"taste\" + 0.015*\"branch\"'),\n",
       " (14,\n",
       "  '0.029*\"sorry\" + 0.028*\"send\" + 0.025*\"reddit\" + 0.022*\"message\" + 0.021*\"answer\" + 0.021*\"video\" + 0.019*\"view\" + 0.019*\"detail\" + 0.018*\"edit\" + 0.018*\"link\"'),\n",
       " (15,\n",
       "  '0.043*\"second\" + 0.041*\"fast\" + 0.037*\"speed\" + 0.034*\"traffic\" + 0.031*\"pass\" + 0.030*\"limit\" + 0.027*\"safe\" + 0.021*\"vehicle\" + 0.019*\"slow\" + 0.016*\"lawyer\"'),\n",
       " (16,\n",
       "  '0.034*\"culture\" + 0.026*\"government\" + 0.023*\"community\" + 0.023*\"hate\" + 0.022*\"western\" + 0.020*\"europe\" + 0.020*\"state\" + 0.019*\"exist\" + 0.015*\"european\" + 0.014*\"expat\"'),\n",
       " (17,\n",
       "  '0.056*\"order\" + 0.054*\"restaurant\" + 0.050*\"delivery\" + 0.024*\"drink\" + 0.024*\"taxi\" + 0.018*\"deliver\" + 0.017*\"directly\" + 0.016*\"address\" + 0.016*\"careem\" + 0.015*\"border\"'),\n",
       " (18,\n",
       "  '0.018*\"able\" + 0.015*\"credit\" + 0.014*\"provide\" + 0.013*\"consider\" + 0.013*\"save\" + 0.013*\"advice\" + 0.012*\"increase\" + 0.011*\"worth\" + 0.011*\"book\" + 0.010*\"level\"'),\n",
       " (19,\n",
       "  '0.025*\"india\" + 0.021*\"hire\" + 0.019*\"earn\" + 0.016*\"manager\" + 0.016*\"white\" + 0.014*\"black\" + 0.013*\"coffee\" + 0.013*\"financial\" + 0.012*\"position\" + 0.012*\"team\"'),\n",
       " (20,\n",
       "  '0.045*\"watch\" + 0.041*\"movie\" + 0.027*\"female\" + 0.025*\"land\" + 0.025*\"fuck\" + 0.024*\"seriously\" + 0.022*\"enjoy\" + 0.022*\"illegal\" + 0.021*\"plate\" + 0.021*\"fire\"'),\n",
       " (21,\n",
       "  '0.054*\"hour\" + 0.036*\"week\" + 0.031*\"insurance\" + 0.030*\"car\" + 0.024*\"minute\" + 0.023*\"license\" + 0.020*\"late\" + 0.019*\"center\" + 0.017*\"cover\" + 0.016*\"early\"'),\n",
       " (22,\n",
       "  '0.049*\"sell\" + 0.045*\"open\" + 0.038*\"mall\" + 0.030*\"buy\" + 0.028*\"market\" + 0.027*\"store\" + 0.025*\"shop\" + 0.019*\"brand\" + 0.018*\"product\" + 0.017*\"beach\"'),\n",
       " (23,\n",
       "  '0.037*\"website\" + 0.036*\"learn\" + 0.029*\"write\" + 0.026*\"wish\" + 0.026*\"word\" + 0.020*\"apply\" + 0.018*\"information\" + 0.018*\"online\" + 0.018*\"internet\" + 0.015*\"language\"'),\n",
       " (24,\n",
       "  '0.042*\"indian\" + 0.032*\"nationality\" + 0.029*\"racism\" + 0.028*\"dude\" + 0.027*\"racist\" + 0.026*\"emirati\" + 0.026*\"news\" + 0.022*\"emiratis\" + 0.018*\"source\" + 0.016*\"app\"')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_5.print_topics(num_topics = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2f1a88e8-da43-4be6-9234-ae29b9275b11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[report, passport, travel, process, emirate, email, contract, wear, cancel, court]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[owner, head, turn, hotel, room, light, lmao, bother, curious, fresh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hand, face, sense, hold, common, literally, public, short, stupid, absolutely]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[away, date, walk, stand, park, girl, line, security, drop, seat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[arab, landlord, arabic, difference, raise, chicken, saudi, shawarma, fake, bear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[notice, quality, scam, clean, minimum, poor, complain, wage, super, apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[care, accept, allow, respect, rule, muslim, treat, follow, force, okay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[speak, house, deal, remember, agent, estate, english, lose, afford, villa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[rent, area, apartment, cheap, expensive, building, depend, canada, plan, trip]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[bank, phone, account, charge, soon, bill, possible, parking, sharjah, transaction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[station, build, interest, metro, fill, recommend, advance, available, special, solution]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[kid, school, middle, parent, child, class, father, meet, wife, summer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[property, test, worker, rich, rate, covid, million, result, condition, burger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[dhabi, true, sound, tip, private, miss, near, crazy, taste, branch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[sorry, send, reddit, message, answer, video, view, detail, edit, link]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[second, fast, speed, traffic, pass, limit, safe, vehicle, slow, lawyer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[culture, government, community, hate, western, europe, state, exist, european, expat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[order, restaurant, delivery, drink, taxi, deliver, directly, address, careem, border]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[able, credit, provide, consider, save, advice, increase, worth, book, level]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[india, hire, earn, manager, white, black, coffee, financial, position, team]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[watch, movie, female, land, fuck, seriously, enjoy, illegal, plate, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[hour, week, insurance, car, minute, license, late, center, cover, early]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[sell, open, mall, buy, market, store, shop, brand, product, beach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[website, learn, write, wish, word, apply, information, online, internet, language]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[indian, nationality, racism, dude, racist, emirati, news, emiratis, source, app]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           words\n",
       "topic                                                                                           \n",
       "0             [report, passport, travel, process, emirate, email, contract, wear, cancel, court]\n",
       "1                          [owner, head, turn, hotel, room, light, lmao, bother, curious, fresh]\n",
       "2                [hand, face, sense, hold, common, literally, public, short, stupid, absolutely]\n",
       "3                              [away, date, walk, stand, park, girl, line, security, drop, seat]\n",
       "4              [arab, landlord, arabic, difference, raise, chicken, saudi, shawarma, fake, bear]\n",
       "5                    [notice, quality, scam, clean, minimum, poor, complain, wage, super, apple]\n",
       "6                       [care, accept, allow, respect, rule, muslim, treat, follow, force, okay]\n",
       "7                    [speak, house, deal, remember, agent, estate, english, lose, afford, villa]\n",
       "8                [rent, area, apartment, cheap, expensive, building, depend, canada, plan, trip]\n",
       "9            [bank, phone, account, charge, soon, bill, possible, parking, sharjah, transaction]\n",
       "10     [station, build, interest, metro, fill, recommend, advance, available, special, solution]\n",
       "11                       [kid, school, middle, parent, child, class, father, meet, wife, summer]\n",
       "12               [property, test, worker, rich, rate, covid, million, result, condition, burger]\n",
       "13                          [dhabi, true, sound, tip, private, miss, near, crazy, taste, branch]\n",
       "14                       [sorry, send, reddit, message, answer, video, view, detail, edit, link]\n",
       "15                      [second, fast, speed, traffic, pass, limit, safe, vehicle, slow, lawyer]\n",
       "16        [culture, government, community, hate, western, europe, state, exist, european, expat]\n",
       "17        [order, restaurant, delivery, drink, taxi, deliver, directly, address, careem, border]\n",
       "18                 [able, credit, provide, consider, save, advice, increase, worth, book, level]\n",
       "19                 [india, hire, earn, manager, white, black, coffee, financial, position, team]\n",
       "20                    [watch, movie, female, land, fuck, seriously, enjoy, illegal, plate, fire]\n",
       "21                     [hour, week, insurance, car, minute, license, late, center, cover, early]\n",
       "22                           [sell, open, mall, buy, market, store, shop, brand, product, beach]\n",
       "23           [website, learn, write, wish, word, apply, information, online, internet, language]\n",
       "24             [indian, nationality, racism, dude, racist, emirati, news, emiratis, source, app]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset of topcis and topic representation\n",
    "num_topics = model_5.num_topics\n",
    "\n",
    "topics_words = []\n",
    "\n",
    "for topic in range(num_topics):\n",
    "    topic_words = model_5.show_topic(topic, topn = 10)\n",
    "    words = [word[0] for word in topic_words]\n",
    "    topics_words.append({\"topic\": topic, \"words\": words})\n",
    "    \n",
    "\n",
    "#create a dataframe\n",
    "model_5_topics_df = pd.DataFrame(topics_words)\n",
    "model_5_topics_df.set_index('topic', inplace =True)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(model_5_topics_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f058f39b-d94e-4861-8077-b78cf9a6a37d",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>topic 0: label--><em><b>immigration_travel</b></em></li><br>\n",
    "    <li>topic 1:terms not belonging to a single coherent theme or related themes</li><br>\n",
    "    <li>topic 2: terms not belonging to a single coherent theme or related themes</li><br>\n",
    "    <li>topic 3: label --><em><b>social_activities</b></em></li><br>\n",
    "    <li>topic 4: </li><br>\n",
    "    <li>topic 5: </li><br>\n",
    "    <li>topic 6: label --><em><b>culture_norms</b></em></li><br>\n",
    "    <li>topic 7: five of the terms(<em>'house', 'deal', 'agent', 'estate', 'villa'</em>) belong to label --><em><b>real_estate_housing</b></em></li><br>\n",
    "    <li>topic 8: a repeat time of topic 7, with terms like <em> 'rent', 'area', 'apartment', 'cheap', 'expensive', 'building'</em> belonging to label --><em><b>real_estate_housing</b></em></li><br>\n",
    "    <li>topic 9: <em> 'bank', 'account', 'charge', 'transaction'</em>, label --><em><b>financial_services</b></em></li><br>\n",
    "    <li>topic 10: </li><br>\n",
    "    <li>topic 11: topic 1: Label --> <em><b>social_relationships</b></em></li><br>\n",
    "    <li>topic 12: a jumble of terms, with some that can be labelled <em><b>health.covid</b></em></li><br>\n",
    "    <li>topic 13: </li><br>\n",
    "    <li>topic 14: label--><em><b>communication_media</b></em> **not of interest**</li><br>\n",
    "    <li>topic 15: label--><em><b>urban_mobility.traffic_regulations</b></em></li><br>\n",
    "    <li>topic 16: a jumble of terms, relating to different themes</li><br>\n",
    "    <li>topic 17: label--><em><b>food_dining_services</b></em></li><br>\n",
    "    <li>topic 18: do not relate to themes considered</li>\n",
    "    <li>topic 19: label--><em><b>employment_opportunities</b></em></li><br>\n",
    "    <li>topic 20: a jumble of terms belong to unrelated themes</li><br>\n",
    "    <li>topic 21: some terms like <em> 'insurance', 'car', 'license', 'center', 'cover'</em> that relate to label--><em><b>urban_mobility.car_ownership</b></em></li><br>\n",
    "    <li>topic 22: label--><em><b>shopping_services</b></em></li><br>\n",
    "    <li>topic 23: a jumble of terms unrelated to themes considered</li><br>\n",
    "    <li>topic 24: label --><em><b>international_communities_inclusion</b></em></li><br>\n",
    "   \n",
    "    \n",
    "        \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9afb72-0eb6-42fb-a8ea-b47fc878dc20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "projectenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
