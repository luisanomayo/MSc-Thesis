{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218c120d-929d-459d-a504-66ecb140f636",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h1><b>Topic Modelling with LDA: Evaluation</b></h1>\n",
    "    <p style = \"color: black\"> Using LDA model on pre-processed data. Stop word removal during pre-processing is limited to common english stop words, top 100 most common words, and words occuring less than 10 times.<br>Any further stop word removal will be done when creating bag of words with the gensim library \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9413769-204d-4f78-8ed0-492d1b1241ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>I. Setting Up Environment</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f558492-64cf-4cb4-b59e-3832e2587055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data transformation libraries\n",
    "import pandas as pd\n",
    "from pandas import option_context\n",
    "import numpy as np\n",
    "import ast\n",
    "import csv\n",
    "\n",
    "#NLP specific libraries\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#topic modelling libraries\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, CoherenceModel, LdaMulticore\n",
    "\n",
    "\n",
    "#for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "#others\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bdf6c5c-3d5e-41d5-beb9-442ffffb2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed so that code output is deterministic\n",
    "random.seed(200)  # Set the seed for Python's random module\n",
    "np.random.seed(200)  # Set the seed for NumPy's random module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac14eb5-b63b-46de-ae55-5fb6589e31e0",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>II. Import Data</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b0ba03-939b-4f3a-857b-ede3e330fa64",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>a. Import preprocessed data</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01f4305-54c2-4988-a62e-c2e960f8a295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>date_created</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d18gk</td>\n",
       "      <td>2012-09-25 07:57:13</td>\n",
       "      <td>2012</td>\n",
       "      <td>Yet i stared at the picture for a good 45 seco...</td>\n",
       "      <td>stare picture second miss</td>\n",
       "      <td>[stare, picture, second, miss]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d2fss</td>\n",
       "      <td>2012-09-25 09:13:23</td>\n",
       "      <td>2012</td>\n",
       "      <td>[FYSR] = from your sister subreddit.\\n\\nIMO, i...</td>\n",
       "      <td>sister subreddit mildly interesting chance eve...</td>\n",
       "      <td>[sister, subreddit, mildly, interesting, chanc...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d46es</td>\n",
       "      <td>2012-09-25 12:32:08</td>\n",
       "      <td>2012</td>\n",
       "      <td>common give prince william harry a break he ju...</td>\n",
       "      <td>common prince harry break</td>\n",
       "      <td>[common, prince, harry, break]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>submission</td>\n",
       "      <td>1sur9h</td>\n",
       "      <td>2013-12-14 11:02:08</td>\n",
       "      <td>2013</td>\n",
       "      <td>Took this image of the Burj Khalifa from Souk ...</td>\n",
       "      <td>image burj khalifa souk bahar yesterday build ...</td>\n",
       "      <td>[image, burj, khalifa, souk, bahar, yesterday,...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>ce1gf68</td>\n",
       "      <td>2013-12-14 12:07:24</td>\n",
       "      <td>2013</td>\n",
       "      <td>Sorry pal, but you took an artistically not-so...</td>\n",
       "      <td>sorry impressive photo landmark resident karma...</td>\n",
       "      <td>[sorry, impressive, photo, landmark, resident,...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_type       ID         date_created  year  \\\n",
       "0     comment  c6d18gk  2012-09-25 07:57:13  2012   \n",
       "1     comment  c6d2fss  2012-09-25 09:13:23  2012   \n",
       "2     comment  c6d46es  2012-09-25 12:32:08  2012   \n",
       "3  submission   1sur9h  2013-12-14 11:02:08  2013   \n",
       "4     comment  ce1gf68  2013-12-14 12:07:24  2013   \n",
       "\n",
       "                                           long_text  \\\n",
       "0  Yet i stared at the picture for a good 45 seco...   \n",
       "1  [FYSR] = from your sister subreddit.\\n\\nIMO, i...   \n",
       "2  common give prince william harry a break he ju...   \n",
       "3  Took this image of the Burj Khalifa from Souk ...   \n",
       "4  Sorry pal, but you took an artistically not-so...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                          stare picture second miss   \n",
       "1  sister subreddit mildly interesting chance eve...   \n",
       "2                          common prince harry break   \n",
       "3  image burj khalifa souk bahar yesterday build ...   \n",
       "4  sorry impressive photo landmark resident karma...   \n",
       "\n",
       "                                              tokens  word_count  \n",
       "0                     [stare, picture, second, miss]           4  \n",
       "1  [sister, subreddit, mildly, interesting, chanc...          18  \n",
       "2                     [common, prince, harry, break]           4  \n",
       "3  [image, burj, khalifa, souk, bahar, yesterday,...          11  \n",
       "4  [sorry, impressive, photo, landmark, resident,...           8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import cleaned and pre-processed data\n",
    "\n",
    "def list_converter(text):\n",
    "    #to revert list->str conversion from pd.read_csv\n",
    "    return ast.literal_eval(text)\n",
    "\n",
    "\n",
    "data = pd.read_csv('../../../Data/lda_train.csv', converters ={'tokens':list_converter})\n",
    "data = data.drop(columns = ['index'])\n",
    "data.sort_values(by='date_created', inplace = True, ignore_index = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "350b4c13-7c16-416f-95c7-447a892091c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61376 entries, 0 to 61375\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   text_type     61376 non-null  object\n",
      " 1   ID            61376 non-null  object\n",
      " 2   date_created  61376 non-null  object\n",
      " 3   year          61376 non-null  int64 \n",
      " 4   long_text     61376 non-null  object\n",
      " 5   clean_text    61376 non-null  object\n",
      " 6   tokens        61376 non-null  object\n",
      " 7   word_count    61376 non-null  int64 \n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b44e9-1dc2-451f-b23a-b877d4a05529",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>b. Import Bag-of-Words</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdeabd3d-4f58-4aa6-8792-6ba51d801b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data['tokens'].tolist()\n",
    "# Create bigrams - code from gensim documentation page\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)\n",
    "            \n",
    "dictionary = corpora.Dictionary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab49f2f-43ea-41b9-921a-57b4b389e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/bow_corpus.pkl\", \"rb\") as f:\n",
    "    bow = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92931959-a8bf-49e4-85b6-216e043713cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1), (3, 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5963f8a-c023-458c-a6f5-2c155a8a5637",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>c. Import Word2Vec Model</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f857bc4-d225-4775-bf06-bcdd40d61d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('../models/w2v_model_lda_bigrams.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c6a6e7-58d4-4b48-9b48-59b2216b2199",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>III. LDA Model Visual Evaluation</b></h2>\n",
    "</span>\n",
    "<p>A review of the top 10 words in each topic to determine the following:\n",
    "    <ul>\n",
    "    <li>Do they make sense?</li>\n",
    "    <li>can the topic be given a label?</li>\n",
    "    <li>Using a sample of the submissions in the training data, determine if the topics are accurate\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5377f02b-904b-4d97-8685-d4c935cb0d7c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#functions for evaluating the models\n",
    "#function to compute coherence, diversity and perplexity metrics\n",
    "def eval_metrics (lda_model, docs, dictionary, num_topics, corpus, top_n = 10):\n",
    "    #Compute c_v score\n",
    "    c_v = CoherenceModel(model=lda_model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "    cv_lda = c_v.get_coherence()\n",
    "    \n",
    "    # Compute u_mass score\n",
    "    u_mass = CoherenceModel(model=lda_model, texts=docs, dictionary=dictionary, coherence='u_mass')\n",
    "    umass_lda = u_mass.get_coherence()\n",
    "    \n",
    "    # Compute c_npmi score\n",
    "    c_npmi = CoherenceModel(model=lda_model, texts=docs, dictionary=dictionary, coherence='c_npmi')\n",
    "    cnpmi_lda = c_npmi.get_coherence()\n",
    "    \n",
    "    # Compute perplexity\n",
    "    perplexity = lda_model.log_perplexity(corpus)\n",
    "    \n",
    "    # Compute topic diversity\n",
    "    top_words = [word for topic_id in range(num_topics) for word, _ in lda_model.show_topic(topic_id, topn=top_n)]\n",
    "    diversity = len(set(top_words)) / (num_topics * top_n)\n",
    "    \n",
    "    print(f\"For {num_topics} topics:\\nCoherence(c_v) = {cv_lda},\\nCoherence(c_npmi) = {cnpmi_lda},\\nCoherence(u_mass) = {umass_lda},\\nPerplexity = {perplexity},\\nTopic Diversity = {diversity}\\n\")\n",
    "    \n",
    "    #return cv_lda, umass_lda, cnpmi_lda, perplexity, diversity\n",
    "\n",
    "#function to check average word similarities for the topics \n",
    "def average_similarity(lda_model, num_topics, w2v_model, top_n=10):\n",
    "    #extract top 10 words for each topic\n",
    "    top_words_per_topic =[] \n",
    "    for topic_id in range(num_topics):\n",
    "        top_words = lda_model.show_topic(topic_id, topn=top_n)\n",
    "        top_words = [word for word, _ in top_words]\n",
    "        top_words_per_topic.append(top_words)\n",
    "        \n",
    "    # 2. Compute pairwise similarities for each topic\n",
    "    average_similarities = []\n",
    "    for top_words in top_words_per_topic:\n",
    "        total_similarity = 0\n",
    "        count = 0\n",
    "        for i in range(len(top_words)):\n",
    "            for j in range(i+1, len(top_words)):  # Compare each word with the words after it\n",
    "                if top_words[i] in w2v_model.wv and top_words[j] in w2v_model.wv:\n",
    "                    similarity = w2v_model.wv.similarity(top_words[i], top_words[j])\n",
    "                    total_similarity += similarity\n",
    "                    count += 1\n",
    "        average_similarity = total_similarity / count if count != 0 else 0\n",
    "        average_similarities.append(average_similarity)\n",
    "    #print average similarities for each topic\n",
    "    for idx, avg_sim in enumerate(average_similarities):\n",
    "        print(f\"Average similarity for topic {idx}: {avg_sim:.4f}\")\n",
    "        \n",
    "    #return average_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cfde49-65c1-4ceb-9f21-4e19468b0058",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>a. model 1: 5 topics</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60667593-2a2e-4411-9439-fd75f708f807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_1 = LdaModel.load('../models/model_1_5tpcs/lda_model_1_5tpcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb772512-6caa-4ed6-bf33-daad2600f49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 5 topics:\n",
      "Coherence(c_v) = 0.6049680135364921,\n",
      "Coherence(c_npmi) = 0.01809764921147028,\n",
      "Coherence(u_mass) = -3.6348576844708056,\n",
      "Perplexity = -8.133242504850717,\n",
      "Topic Diversity = 1.0\n",
      "\n",
      "Average similarity for topic 0: 0.4982\n",
      "Average similarity for topic 1: 0.4522\n",
      "Average similarity for topic 2: 0.2859\n",
      "Average similarity for topic 3: 0.4426\n",
      "Average similarity for topic 4: 0.5138\n"
     ]
    }
   ],
   "source": [
    "#quantitative evaluation\n",
    "eval_metrics (lda_model = model_1,docs = docs,\n",
    "              dictionary = dictionary, num_topics = model_1.num_topics, \n",
    "               corpus = bow, top_n = 10)\n",
    "\n",
    "average_similarity(lda_model = model_1, num_topics = model_1.num_topics, \n",
    "                   w2v_model = w2v_model, top_n=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e337866c-e892-47d3-96db-82353ed6f23c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"report\" + 0.012*\"area\" + 0.011*\"car\" + 0.011*\"close\" + 0.010*\"fast\" + 0.009*\"speed\" + 0.008*\"metro\" + 0.008*\"traffic\" + 0.008*\"park\" + 0.008*\"turn\"'),\n",
       " (1,\n",
       "  '0.010*\"bank\" + 0.009*\"rent\" + 0.007*\"sell\" + 0.007*\"send\" + 0.007*\"week\" + 0.007*\"property\" + 0.007*\"cheap\" + 0.006*\"order\" + 0.006*\"option\" + 0.006*\"charge\"'),\n",
       " (2,\n",
       "  '0.010*\"mall\" + 0.010*\"walk\" + 0.008*\"reddit\" + 0.007*\"video\" + 0.007*\"stuff\" + 0.006*\"outside\" + 0.006*\"night\" + 0.006*\"tip\" + 0.006*\"visit\" + 0.006*\"social\"'),\n",
       " (3,\n",
       "  '0.007*\"kid\" + 0.006*\"care\" + 0.006*\"hard\" + 0.006*\"speak\" + 0.006*\"sorry\" + 0.006*\"culture\" + 0.006*\"learn\" + 0.006*\"situation\" + 0.006*\"school\" + 0.005*\"believe\"'),\n",
       " (4,\n",
       "  '0.007*\"passport\" + 0.006*\"allow\" + 0.006*\"government\" + 0.006*\"apply\" + 0.006*\"travel\" + 0.005*\"base\" + 0.005*\"rule\" + 0.005*\"employee\" + 0.005*\"india\" + 0.005*\"job\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.print_topics(num_topics = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5812a5b9-2b2f-4412-a43e-d207831695d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[report, area, car, close, fast, speed, metro, traffic, park, turn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[bank, rent, sell, send, week, property, cheap, order, option, charge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[mall, walk, reddit, video, stuff, outside, night, tip, visit, social]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[kid, care, hard, speak, sorry, culture, learn, situation, school, believe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[passport, allow, government, apply, travel, base, rule, employee, india, job]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  \\\n",
       "0      0   \n",
       "1      1   \n",
       "2      2   \n",
       "3      3   \n",
       "4      4   \n",
       "\n",
       "                                                                            words  \n",
       "0             [report, area, car, close, fast, speed, metro, traffic, park, turn]  \n",
       "1          [bank, rent, sell, send, week, property, cheap, order, option, charge]  \n",
       "2          [mall, walk, reddit, video, stuff, outside, night, tip, visit, social]  \n",
       "3     [kid, care, hard, speak, sorry, culture, learn, situation, school, believe]  \n",
       "4  [passport, allow, government, apply, travel, base, rule, employee, india, job]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset of topcis and topic representation\n",
    "num_topics = model_1.num_topics\n",
    "\n",
    "topics_words = []\n",
    "\n",
    "for topic in range(num_topics):\n",
    "    topic_words = model_1.show_topic(topic, topn = 10)\n",
    "    words = [word[0] for word in topic_words]\n",
    "    topics_words.append({\"topic\": topic, \"words\": words})\n",
    "    \n",
    "\n",
    "#create a dataframe\n",
    "model_1_topics_df = pd.DataFrame(topics_words)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(model_1_topics_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613e581-ca4a-4a0c-a4b0-2e9aa6490bc5",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>topic 0: <em>'car', 'fast', 'speed', 'park', 'turn',</em> --> <em><b>urban_mobility</b></em>.\n",
    "    That means of the top 10 words, 5 relate to the same topic.</li><br>\n",
    "    <li>topic 1: <em> 'rent', 'property', 'cheap'</em> --> <em><b>accommodation</b></em>. However, the terms <em> 'sell', 'send', 'cheap', 'order', 'option', 'charge'</em> --> <em><b>shopping and purchases</b></em>. This topic contains two sub-topics.</li><br>\n",
    "    <li>topic 2: <em>'mall', 'walk', 'outside', 'night', 'visit'</em>might be said to indicate <em><b>recreation</b></em>, but its a bit of a stretch</li><br>\n",
    "    <li>topic 3: contains a jumble of words that don't fit together to specify one coherent topic</li><br>\n",
    "    <li>topic 4: <em>'passport', 'travel' </em>--> <em><b>immigration & travel</b></em>, but the topic also contains <em>'apply', 'base', 'employee', 'job'</em> --> <em><b>employment_opportunities</b></em></li>\n",
    "</ul>\n",
    "<p> Of the five topics extracted, only two have up to 5 coherent words that indicate a topic of interest i.e topic 0 for <em><b>urban_mobility</b></em>, and topic 1 for <em><b>shopping and purchases</b></em>. Topics 1 and 4 have sub topics in them that are not related to each other.This model is likely not the best fit for our data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d25b189f-7146-46ec-876f-4d8ac1d7cb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[report, area, car, close, fast, speed, metro, traffic, park, turn]</td>\n",
       "      <td>urban_mobility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[bank, rent, sell, send, week, property, cheap, order, option, charge]</td>\n",
       "      <td>accommodation/shopping_pur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[mall, walk, reddit, video, stuff, outside, night, tip, visit, social]</td>\n",
       "      <td>undefined/recreation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[kid, care, hard, speak, sorry, culture, learn, situation, school, believe]</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[passport, allow, government, apply, travel, base, rule, employee, india, job]</td>\n",
       "      <td>employment_opportunities/immigration_travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  \\\n",
       "0      0   \n",
       "1      1   \n",
       "2      2   \n",
       "3      3   \n",
       "4      4   \n",
       "\n",
       "                                                                            words  \\\n",
       "0             [report, area, car, close, fast, speed, metro, traffic, park, turn]   \n",
       "1          [bank, rent, sell, send, week, property, cheap, order, option, charge]   \n",
       "2          [mall, walk, reddit, video, stuff, outside, night, tip, visit, social]   \n",
       "3     [kid, care, hard, speak, sorry, culture, learn, situation, school, believe]   \n",
       "4  [passport, allow, government, apply, travel, base, rule, employee, india, job]   \n",
       "\n",
       "                                         label  \n",
       "0                               urban_mobility  \n",
       "1                   accommodation/shopping_pur  \n",
       "2                         undefined/recreation  \n",
       "3                                    undefined  \n",
       "4  employment_opportunities/immigration_travel  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#attach topic label to topic terms\n",
    "\n",
    "topic_label ={\n",
    "    0: \"urban_mobility\",\n",
    "    1: \"accommodation/shopping_pur\",\n",
    "    2: \"undefined/recreation\",\n",
    "    3: \"undefined\",\n",
    "    4: \"employment_opportunities/immigration_travel\",\n",
    "}\n",
    "\n",
    "model_1_topics_df['label'] = model_1_topics_df['topic'].map(topic_label)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(model_1_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e702f061-7699-4567-93af-a4fd0425f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include column for most probable topic for each entry\n",
    "\n",
    "top_topic_per_document = []\n",
    "\n",
    "for doc in bow:\n",
    "    topics = model_1.get_document_topics(doc, minimum_probability = 0)\n",
    "    top_topic = sorted(topics, key=lambda x: x[1], reverse = True)[0][0]\n",
    "    top_topic_per_document.append(top_topic)\n",
    "    \n",
    "#add column to data dataframe for the selected topic\n",
    "data['top_topic'] = top_topic_per_document    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e72a643-1648-41f5-bba6-ba6dab8e89b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>date_created</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>top_topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d18gk</td>\n",
       "      <td>2012-09-25 07:57:13</td>\n",
       "      <td>2012</td>\n",
       "      <td>Yet i stared at the picture for a good 45 seco...</td>\n",
       "      <td>stare picture second miss</td>\n",
       "      <td>[stare, picture, second, miss]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d2fss</td>\n",
       "      <td>2012-09-25 09:13:23</td>\n",
       "      <td>2012</td>\n",
       "      <td>[FYSR] = from your sister subreddit.\\n\\nIMO, i...</td>\n",
       "      <td>sister subreddit mildly interesting chance eve...</td>\n",
       "      <td>[sister, subreddit, mildly, interesting, chanc...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>accommodation/shopping_pur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d46es</td>\n",
       "      <td>2012-09-25 12:32:08</td>\n",
       "      <td>2012</td>\n",
       "      <td>common give prince william harry a break he ju...</td>\n",
       "      <td>common prince harry break</td>\n",
       "      <td>[common, prince, harry, break]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>submission</td>\n",
       "      <td>1sur9h</td>\n",
       "      <td>2013-12-14 11:02:08</td>\n",
       "      <td>2013</td>\n",
       "      <td>Took this image of the Burj Khalifa from Souk ...</td>\n",
       "      <td>image burj khalifa souk bahar yesterday build ...</td>\n",
       "      <td>[image, burj, khalifa, souk, bahar, yesterday,...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined/recreation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>ce1gf68</td>\n",
       "      <td>2013-12-14 12:07:24</td>\n",
       "      <td>2013</td>\n",
       "      <td>Sorry pal, but you took an artistically not-so...</td>\n",
       "      <td>sorry impressive photo landmark resident karma...</td>\n",
       "      <td>[sorry, impressive, photo, landmark, resident,...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined/recreation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_type       ID         date_created  year  \\\n",
       "0     comment  c6d18gk  2012-09-25 07:57:13  2012   \n",
       "1     comment  c6d2fss  2012-09-25 09:13:23  2012   \n",
       "2     comment  c6d46es  2012-09-25 12:32:08  2012   \n",
       "3  submission   1sur9h  2013-12-14 11:02:08  2013   \n",
       "4     comment  ce1gf68  2013-12-14 12:07:24  2013   \n",
       "\n",
       "                                           long_text  \\\n",
       "0  Yet i stared at the picture for a good 45 seco...   \n",
       "1  [FYSR] = from your sister subreddit.\\n\\nIMO, i...   \n",
       "2  common give prince william harry a break he ju...   \n",
       "3  Took this image of the Burj Khalifa from Souk ...   \n",
       "4  Sorry pal, but you took an artistically not-so...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                          stare picture second miss   \n",
       "1  sister subreddit mildly interesting chance eve...   \n",
       "2                          common prince harry break   \n",
       "3  image burj khalifa souk bahar yesterday build ...   \n",
       "4  sorry impressive photo landmark resident karma...   \n",
       "\n",
       "                                              tokens  word_count  top_topic  \\\n",
       "0                     [stare, picture, second, miss]           4          3   \n",
       "1  [sister, subreddit, mildly, interesting, chanc...          18          1   \n",
       "2                     [common, prince, harry, break]           4          3   \n",
       "3  [image, burj, khalifa, souk, bahar, yesterday,...          11          2   \n",
       "4  [sorry, impressive, photo, landmark, resident,...           8          2   \n",
       "\n",
       "                        label  \n",
       "0                   undefined  \n",
       "1  accommodation/shopping_pur  \n",
       "2                   undefined  \n",
       "3        undefined/recreation  \n",
       "4        undefined/recreation  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping from df1\n",
    "topic_to_label = model_1_topics_df.set_index('topic')['label'].to_dict()\n",
    "\n",
    "# Map the values to df2\n",
    "data['label'] = data['top_topic'].map(topic_to_label)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96342432-427f-40f4-8e1a-ce9feb0c7078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include column for second most probable topic for each entry\n",
    "\n",
    "top_topic_per_document = []\n",
    "\n",
    "for doc in bow:\n",
    "    topics = model_1.get_document_topics(doc)\n",
    "    top_topic = sorted(topics, key=lambda x: x[1], reverse = True)[1][0]\n",
    "    top_topic_per_document.append(top_topic)\n",
    "    \n",
    "#add column to data dataframe for the selected topic\n",
    "data['topic_2'] = top_topic_per_document   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4951f949-6fc6-442f-a1bb-ff05db44a727",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_created</th>\n",
       "      <th>long_text</th>\n",
       "      <th>top_topic</th>\n",
       "      <th>label</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38303</th>\n",
       "      <td>2022-07-17 08:23:29</td>\n",
       "      <td>Anybody else been forced to start a business after losing a job, and wake up every morning wishing you never had to open your eyes? Every day is a minor heart attack asking yourself, \"can I do this ethically?\" All you see is people conning each other, and all you hear is, \"this is how you have to play the game\" I've been conned by people who I thought were friends. And then been in business with another \"friend\" with questionable business practices. I'm not suicidal, but I do keep wishing this would all end.</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined/recreation</td>\n",
       "      <td>3</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59518</th>\n",
       "      <td>2023-06-18 20:08:38</td>\n",
       "      <td>require some suggestions - banking / accounts / loans Hi All,\\n\\nNeed some suggestions or opinions and better personal experiences.\\n\\nI have been banking and have account and credit cards with a bank here for almost a decade. It's a conventional bank, but sooner or later I am going to go for a home loan - for which I would prefer an Islamic bank. Should I open some account with an Islamic bank to have some relationship over period of time OR it doesn't matter - when the need to loan arises I can go for looking around for loan and based on my AECB reports bank would provide rates - so effectively meaning that longer or shorter relationship wouldn't mean anything it just that transaction and the score at the point of time which would matter?</td>\n",
       "      <td>1</td>\n",
       "      <td>accommodation/shopping_pur</td>\n",
       "      <td>4</td>\n",
       "      <td>employment_opportunities/immigration_travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>2020-02-10 10:02:39</td>\n",
       "      <td>Current Global Economic Situation</td>\n",
       "      <td>4</td>\n",
       "      <td>employment_opportunities/immigration_travel</td>\n",
       "      <td>3</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60089</th>\n",
       "      <td>2023-06-19 20:13:26</td>\n",
       "      <td>I need to get a broken hard disk repaired. I’ve got a ton of data on it with no backup. Any idea if there are any reliable places in Dubai or Sharjah for data recovery ? Tried searching online and didn’t find anything convincing.</td>\n",
       "      <td>1</td>\n",
       "      <td>accommodation/shopping_pur</td>\n",
       "      <td>3</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61240</th>\n",
       "      <td>2023-06-21 17:53:14</td>\n",
       "      <td>What to do when the neighbour parks like this? Hello Dubai community!\\n\\nGuys it is getting out of hands, I never met this guy, but he keeps on parking like this recently. \\n\\nAny advice from professional residents how to deal with this?</td>\n",
       "      <td>4</td>\n",
       "      <td>employment_opportunities/immigration_travel</td>\n",
       "      <td>0</td>\n",
       "      <td>urban_mobility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>2020-05-11 11:11:08</td>\n",
       "      <td>Any news on gyms reopening? Does anybody have an insider scoop on when they're reopening?\\n\\nNewspaper people if you are reading you can chime in. In the form of a news article in 2 days or something.</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined/recreation</td>\n",
       "      <td>4</td>\n",
       "      <td>employment_opportunities/immigration_travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36450</th>\n",
       "      <td>2022-06-06 21:33:34</td>\n",
       "      <td>Experience with Techem ACs I’m planning to move in a building which has Techem as their AC providers. Can someone share their experience with the bills? I am hearing they are quite high.</td>\n",
       "      <td>1</td>\n",
       "      <td>accommodation/shopping_pur</td>\n",
       "      <td>3</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>2020-06-16 13:35:29</td>\n",
       "      <td>Entry permit validity Hey fellas, just came to know that the entry permit validity for residents stuck abroad is 21 days. It’s there on their website and the call centre also confirmed it. But given that many airports are still not opened up to international travel and fewer flights operating, what happens if one is not able to make it into UAE before the 21 day limit? Any input is appreciated. Thanks.</td>\n",
       "      <td>4</td>\n",
       "      <td>employment_opportunities/immigration_travel</td>\n",
       "      <td>1</td>\n",
       "      <td>accommodation/shopping_pur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52698</th>\n",
       "      <td>2023-04-19 08:54:12</td>\n",
       "      <td>Where can I find reasonably-priced jewelry and gold in Dubai? Looking to get my mam a gift Where can I find reasonably-priced jewelry and gold in Dubai? Looking to get my mam a gift</td>\n",
       "      <td>1</td>\n",
       "      <td>accommodation/shopping_pur</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined/recreation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42845</th>\n",
       "      <td>2022-09-22 17:29:32</td>\n",
       "      <td>Any CUD current or former students here? If so, any advice, stories or highlights for a soon to be student at the Uni? General Uni advice appreciated as well. \\nI’m hopefully gonna be attending the spring semester next year and studying Computer Engineering but been getting cold feet since i don’t really know anyone there and don’t know what to expect.\\n\\n\\nAnd while i’ve heard plenty of praise for this Uni i’ve also heard rumors of there being a whole social status hierarchy deal going on which has me nervous-ish.\\n\\nEdit: Just so yk i already heard the song and dance of Unis here not being great but i don’t have a choice but to study in Dubai/Sharjah.</td>\n",
       "      <td>4</td>\n",
       "      <td>employment_opportunities/immigration_travel</td>\n",
       "      <td>2</td>\n",
       "      <td>undefined/recreation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date_created  \\\n",
       "38303  2022-07-17 08:23:29   \n",
       "59518  2023-06-18 20:08:38   \n",
       "3608   2020-02-10 10:02:39   \n",
       "60089  2023-06-19 20:13:26   \n",
       "61240  2023-06-21 17:53:14   \n",
       "6118   2020-05-11 11:11:08   \n",
       "36450  2022-06-06 21:33:34   \n",
       "9116   2020-06-16 13:35:29   \n",
       "52698  2023-04-19 08:54:12   \n",
       "42845  2022-09-22 17:29:32   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            long_text  \\\n",
       "38303                                                                                                                                                                                                                                               Anybody else been forced to start a business after losing a job, and wake up every morning wishing you never had to open your eyes? Every day is a minor heart attack asking yourself, \"can I do this ethically?\" All you see is people conning each other, and all you hear is, \"this is how you have to play the game\" I've been conned by people who I thought were friends. And then been in business with another \"friend\" with questionable business practices. I'm not suicidal, but I do keep wishing this would all end.   \n",
       "59518  require some suggestions - banking / accounts / loans Hi All,\\n\\nNeed some suggestions or opinions and better personal experiences.\\n\\nI have been banking and have account and credit cards with a bank here for almost a decade. It's a conventional bank, but sooner or later I am going to go for a home loan - for which I would prefer an Islamic bank. Should I open some account with an Islamic bank to have some relationship over period of time OR it doesn't matter - when the need to loan arises I can go for looking around for loan and based on my AECB reports bank would provide rates - so effectively meaning that longer or shorter relationship wouldn't mean anything it just that transaction and the score at the point of time which would matter?   \n",
       "3608                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Current Global Economic Situation    \n",
       "60089                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           I need to get a broken hard disk repaired. I’ve got a ton of data on it with no backup. Any idea if there are any reliable places in Dubai or Sharjah for data recovery ? Tried searching online and didn’t find anything convincing.   \n",
       "61240                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   What to do when the neighbour parks like this? Hello Dubai community!\\n\\nGuys it is getting out of hands, I never met this guy, but he keeps on parking like this recently. \\n\\nAny advice from professional residents how to deal with this?   \n",
       "6118                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Any news on gyms reopening? Does anybody have an insider scoop on when they're reopening?\\n\\nNewspaper people if you are reading you can chime in. In the form of a news article in 2 days or something.   \n",
       "36450                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Experience with Techem ACs I’m planning to move in a building which has Techem as their AC providers. Can someone share their experience with the bills? I am hearing they are quite high.   \n",
       "9116                                                                                                                                                                                                                                                                                                                                                            Entry permit validity Hey fellas, just came to know that the entry permit validity for residents stuck abroad is 21 days. It’s there on their website and the call centre also confirmed it. But given that many airports are still not opened up to international travel and fewer flights operating, what happens if one is not able to make it into UAE before the 21 day limit? Any input is appreciated. Thanks.   \n",
       "52698                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Where can I find reasonably-priced jewelry and gold in Dubai? Looking to get my mam a gift Where can I find reasonably-priced jewelry and gold in Dubai? Looking to get my mam a gift   \n",
       "42845                                                                                           Any CUD current or former students here? If so, any advice, stories or highlights for a soon to be student at the Uni? General Uni advice appreciated as well. \\nI’m hopefully gonna be attending the spring semester next year and studying Computer Engineering but been getting cold feet since i don’t really know anyone there and don’t know what to expect.\\n\\n\\nAnd while i’ve heard plenty of praise for this Uni i’ve also heard rumors of there being a whole social status hierarchy deal going on which has me nervous-ish.\\n\\nEdit: Just so yk i already heard the song and dance of Unis here not being great but i don’t have a choice but to study in Dubai/Sharjah.   \n",
       "\n",
       "       top_topic                                        label  topic_2  \\\n",
       "38303          2                         undefined/recreation        3   \n",
       "59518          1                   accommodation/shopping_pur        4   \n",
       "3608           4  employment_opportunities/immigration_travel        3   \n",
       "60089          1                   accommodation/shopping_pur        3   \n",
       "61240          4  employment_opportunities/immigration_travel        0   \n",
       "6118           2                         undefined/recreation        4   \n",
       "36450          1                   accommodation/shopping_pur        3   \n",
       "9116           4  employment_opportunities/immigration_travel        1   \n",
       "52698          1                   accommodation/shopping_pur        2   \n",
       "42845          4  employment_opportunities/immigration_travel        2   \n",
       "\n",
       "                                           label_2  \n",
       "38303                                    undefined  \n",
       "59518  employment_opportunities/immigration_travel  \n",
       "3608                                     undefined  \n",
       "60089                                    undefined  \n",
       "61240                               urban_mobility  \n",
       "6118   employment_opportunities/immigration_travel  \n",
       "36450                                    undefined  \n",
       "9116                    accommodation/shopping_pur  \n",
       "52698                         undefined/recreation  \n",
       "42845                         undefined/recreation  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label_2'] = data['topic_2'].map(topic_to_label)\n",
    "\n",
    "#visually evaluate a small subset of submissions\n",
    "sample = data[data.text_type == 'submission'].sample(n = 10, random_state = 42)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(sample[['date_created', 'long_text', \"top_topic\",'label', \"topic_2\", 'label_2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c1cfd2-318d-45d0-93e9-16c985e6b7db",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434720ea-fa67-4925-b9a1-98e8c2132df7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color: red; font-family: Calibri Light;\">\n",
    "  <h2><b>a. model 2: 10 topics</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d91ac16b-8421-4acd-9478-02f87f00df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = LdaModel.load('../models/model_2_10tpcs/lda_model_2_10tpcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "764d10ce-26c0-427e-a993-14d01b23dd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10 topics:\n",
      "Coherence(c_v) = 0.4895138013398749,\n",
      "Coherence(c_npmi) = -0.02281372631638639,\n",
      "Coherence(u_mass) = -4.798116025994018,\n",
      "Perplexity = -8.206242643921952,\n",
      "Topic Diversity = 1.0\n",
      "\n",
      "Average similarity for topic 0: 0.7092\n",
      "Average similarity for topic 1: 0.5578\n",
      "Average similarity for topic 2: 0.4880\n",
      "Average similarity for topic 3: 0.5324\n",
      "Average similarity for topic 4: 0.5290\n",
      "Average similarity for topic 5: 0.6461\n",
      "Average similarity for topic 6: 0.5922\n",
      "Average similarity for topic 7: 0.3237\n",
      "Average similarity for topic 8: 0.4213\n",
      "Average similarity for topic 9: 0.4569\n"
     ]
    }
   ],
   "source": [
    "#quantitative evaluation\n",
    "eval_metrics (lda_model = model_2,docs = docs,\n",
    "              dictionary = dictionary, num_topics = model_2.num_topics, \n",
    "               corpus = bow, top_n = 10)\n",
    "\n",
    "average_similarity(lda_model = model_2, num_topics = model_2.num_topics, \n",
    "                   w2v_model = w2v_model, top_n=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9024b5ec-2e89-4f00-8479-f2cd7f0e4dd6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.023*\"fast\" + 0.021*\"car\" + 0.021*\"speed\" + 0.020*\"traffic\" + 0.017*\"limit\" + 0.015*\"license\" + 0.012*\"vehicle\" + 0.011*\"slow\" + 0.011*\"ticket\" + 0.011*\"plate\"'),\n",
       " (1,\n",
       "  '0.019*\"bank\" + 0.017*\"rent\" + 0.013*\"property\" + 0.011*\"send\" + 0.011*\"plan\" + 0.011*\"credit\" + 0.011*\"account\" + 0.010*\"sell\" + 0.010*\"market\" + 0.010*\"charge\"'),\n",
       " (2,\n",
       "  '0.010*\"area\" + 0.010*\"hour\" + 0.009*\"week\" + 0.009*\"close\" + 0.008*\"open\" + 0.008*\"walk\" + 0.008*\"visit\" + 0.007*\"mall\" + 0.007*\"away\" + 0.006*\"usually\"'),\n",
       " (3,\n",
       "  '0.030*\"speak\" + 0.029*\"learn\" + 0.028*\"school\" + 0.022*\"word\" + 0.019*\"arabic\" + 0.018*\"english\" + 0.017*\"play\" + 0.016*\"language\" + 0.015*\"rich\" + 0.013*\"fuck\"'),\n",
       " (4,\n",
       "  '0.025*\"test\" + 0.020*\"tip\" + 0.017*\"covid\" + 0.015*\"daily\" + 0.014*\"health\" + 0.012*\"thread\" + 0.010*\"positive\" + 0.009*\"medical\" + 0.009*\"pregnant\" + 0.009*\"june\"'),\n",
       " (5,\n",
       "  '0.018*\"report\" + 0.014*\"reddit\" + 0.012*\"message\" + 0.012*\"website\" + 0.011*\"video\" + 0.010*\"detail\" + 0.010*\"google\" + 0.010*\"write\" + 0.010*\"link\" + 0.008*\"news\"'),\n",
       " (6,\n",
       "  '0.026*\"cheap\" + 0.025*\"order\" + 0.024*\"restaurant\" + 0.023*\"delivery\" + 0.019*\"expensive\" + 0.015*\"quality\" + 0.014*\"contract\" + 0.014*\"bill\" + 0.013*\"store\" + 0.012*\"extra\"'),\n",
       " (7,\n",
       "  '0.021*\"middle\" + 0.015*\"agent\" + 0.015*\"class\" + 0.009*\"crime\" + 0.009*\"east\" + 0.009*\"low\" + 0.009*\"saudi\" + 0.009*\"project\" + 0.008*\"mask\" + 0.008*\"power\"'),\n",
       " (8,\n",
       "  '0.036*\"kid\" + 0.022*\"movie\" + 0.021*\"parent\" + 0.021*\"child\" + 0.021*\"wife\" + 0.019*\"muslim\" + 0.016*\"wear\" + 0.016*\"hate\" + 0.012*\"religion\" + 0.011*\"accident\"'),\n",
       " (9,\n",
       "  '0.007*\"care\" + 0.006*\"consider\" + 0.006*\"situation\" + 0.006*\"passport\" + 0.006*\"culture\" + 0.006*\"hard\" + 0.005*\"mention\" + 0.005*\"matter\" + 0.005*\"arab\" + 0.005*\"believe\"')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_2.print_topics(num_topics = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf521996-5ac5-42ca-93e0-b8b4eed73e7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[fast, car, speed, traffic, limit, license, vehicle, slow, ticket, plate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[bank, rent, property, send, plan, credit, account, sell, market, charge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[area, hour, week, close, open, walk, visit, mall, away, usually]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[speak, learn, school, word, arabic, english, play, language, rich, fuck]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[test, tip, covid, daily, health, thread, positive, medical, pregnant, june]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[report, reddit, message, website, video, detail, google, write, link, news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[cheap, order, restaurant, delivery, expensive, quality, contract, bill, store, extra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[middle, agent, class, crime, east, low, saudi, project, mask, power]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[kid, movie, parent, child, wife, muslim, wear, hate, religion, accident]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[care, consider, situation, passport, culture, hard, mention, matter, arab, believe]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  \\\n",
       "0      0   \n",
       "1      1   \n",
       "2      2   \n",
       "3      3   \n",
       "4      4   \n",
       "5      5   \n",
       "6      6   \n",
       "7      7   \n",
       "8      8   \n",
       "9      9   \n",
       "\n",
       "                                                                                    words  \n",
       "0               [fast, car, speed, traffic, limit, license, vehicle, slow, ticket, plate]  \n",
       "1               [bank, rent, property, send, plan, credit, account, sell, market, charge]  \n",
       "2                       [area, hour, week, close, open, walk, visit, mall, away, usually]  \n",
       "3               [speak, learn, school, word, arabic, english, play, language, rich, fuck]  \n",
       "4            [test, tip, covid, daily, health, thread, positive, medical, pregnant, june]  \n",
       "5            [report, reddit, message, website, video, detail, google, write, link, news]  \n",
       "6  [cheap, order, restaurant, delivery, expensive, quality, contract, bill, store, extra]  \n",
       "7                   [middle, agent, class, crime, east, low, saudi, project, mask, power]  \n",
       "8               [kid, movie, parent, child, wife, muslim, wear, hate, religion, accident]  \n",
       "9    [care, consider, situation, passport, culture, hard, mention, matter, arab, believe]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset of topcis and topic representation\n",
    "num_topics = model_2.num_topics\n",
    "\n",
    "topics_words = []\n",
    "\n",
    "for topic in range(num_topics):\n",
    "    topic_words = model_2.show_topic(topic, topn = 10)\n",
    "    words = [word[0] for word in topic_words]\n",
    "    topics_words.append({\"topic\": topic, \"words\": words})\n",
    "    \n",
    "\n",
    "#create a dataframe\n",
    "model_1_topics_df = pd.DataFrame(topics_words)\n",
    "\n",
    "with option_context('display.max_colwidth', None):\n",
    "    display(model_1_topics_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6735d5-4531-438a-9449-0cffab4c483b",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>topic 0: The top 10 words are all representative terms --> <em><b>urban_mobility</b></em>.</li><br>\n",
    "    <li>topic 1: contains a jumble of words that don't fit together to specify one coherent topic, or a topic of interest</li><br>\n",
    "    <li>topic 2: <em>'passport', 'travel', </em>--> <em><b>immigration & travel</b></em>, but the topic also contains other words that are not representative of that topic, or any coherent topics</li><br>\n",
    "    <li>topic 3: <em> property', 'cheap'</em> -->  <em><b>accommodation</b></em>. However, the terms <em> 'sell', 'cheap', 'order', 'option', 'charge',</em> --> <em><b>shopping and purchases</b></em>. Also, these terms along with <em>'restaurant'</em> --> <em><b> food/dining_experience</b></em> This topic contains three sub-topics.</li><br>\n",
    "    <li>topic 4: contains a jumble of words that don't fit together to specify one coherent topic, or a topic of interest</li><br>\n",
    "    <li>topic 5: contains a jumble of words that don't fit together to specify one coherent topic,  or a topic of interest</li><br>\n",
    "    <li> topic 6: <em>'job', 'hire'</em> --> <em><b>employment_opportunities</b></em>, <em>'loan', 'debt'</em> --> <em><b>finance/financial_services</b></em></li><br>\n",
    "    <li>topic 7: contains a jumble of words that don't fit together to specify one coherent topic,  or a topic of interest</li><br>\n",
    "    <li>topic 8: </li>\n",
    "</ul>\n",
    "<p> Of the five topics extracted, only two have up to 5 coherent words that indicate a topic of interest i.e topic 0 for <em><b>urban_mobility</b></em>, and topic 1 for <em><b>shopping and purchases</b></em>. Topics 1 and 4 have sub topics in them that are not related to each other.<br>This model is likely not the best fit for our data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "85d1c74c-2908-4639-9a16-2b7311d7f337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text_type', 'ID', 'date_created', 'year', 'long_text', 'clean_text',\n",
       "       'tokens', 'word_count', 'top_topic', 'label', 'topic_2', 'label_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d02a5d-6cfc-4338-a147-232321ae3f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "projectenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
